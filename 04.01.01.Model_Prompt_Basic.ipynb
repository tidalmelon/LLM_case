{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e851c63-fbb9-4f99-a92b-26dce2e719a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=./imgs/model_io.jpg width=35% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47454cdf-1217-4fbf-a015-5c981b69e2f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "[langchain documents](https://python.langchain.com/docs/modules/model_io/models/chat/llm_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2806292-4cf0-40eb-9f66-941d282dfab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07b77b43-6e8c-4c03-b08f-ad9c273aaa96",
   "metadata": {},
   "source": [
    "[LangChain-Tutorials](https://github.com/sugarforever/LangChain-Tutorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae4b5d-6079-4ccb-9010-fa84c74919e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1988c104-f3d3-478c-8717-5970120214fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9cffe2-dfe0-440e-a97d-3f42d06e0268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828bc27e-7e3f-4e98-8ed2-185cd4c7daa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40df9c60-458c-4d5d-8808-2c4fa99a02f4",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf225c-c346-4191-86b9-f338b199ed37",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c411207-41c3-420e-909e-2e0f0524a45a",
   "metadata": {},
   "source": [
    "> 提示模版是用来为LLM生成提示.<br>\n",
    "> 目标是： **写出语言模型无关的提示模版.** <font color=green> 这个很重要哦， 可以与大语言模型解耦，估计会根据参数量分层</font> <br>\n",
    "> 通过模型的输入是：字符串提示 或者 `ChatMessage` 提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c9017-89d6-4276-90cf-80aab13b123d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c26e3e8c-de35-4cfc-9997-8fca8f1089bf",
   "metadata": {},
   "source": [
    "### `PromptTemplate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60314715-e895-4276-a73f-86111d0830a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27a5d8c0-5dde-4153-9f97-14a6b87998ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fee14c76-84e0-4e9f-810f-e8ab96710815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"Tell me a {adjective} joke about {content}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1853b3-4634-4a27-992e-69c884331972",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(adjective='funny', content='chickens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076d6e2-842c-46bc-844a-dd5d9812158b",
   "metadata": {},
   "source": [
    "> 包含任意数量的参数，甚至不包括参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3544bef7-0835-47a3-a2d2-1d622f1aedd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f10df8b3-834e-4809-9600-2f1ef7d016d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008bcc10-d3a4-4657-99a1-bf37983d4211",
   "metadata": {},
   "source": [
    "> 额外的验证，可以显示声明`input_variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e49e49-415a-4902-b397-4219ccada831",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for PromptTemplate\n__root__\n  Invalid prompt schema; check for mismatched or missing input parameters. 'content' (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m invalid_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madjective\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTell me a \u001b[39;49m\u001b[38;5;132;43;01m{adjective}\u001b[39;49;00m\u001b[38;5;124;43m joke about \u001b[39;49m\u001b[38;5;132;43;01m{content}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/preventloss/lib/python3.9/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m/opt/conda/envs/preventloss/lib/python3.9/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for PromptTemplate\n__root__\n  Invalid prompt schema; check for mismatched or missing input parameters. 'content' (type=value_error)"
     ]
    }
   ],
   "source": [
    "invalid_prompt = PromptTemplate(input_variables=['adjective'],\n",
    "                                template=\"Tell me a {adjective} joke about {content}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1405d45-7d30-47ef-b4c2-783ab68d7311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2081daec-3130-4008-8ac3-e3177028182b",
   "metadata": {},
   "source": [
    "### `ChatPromptTemplate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e41833-d58d-4553-bc6f-489e1ca80a7a",
   "metadata": {},
   "source": [
    "> 对于ChatModel，提示是一个`ChatMessage`列表<br>\n",
    "> 每一个`ChatMessage`都包含必需字段：`content` 和 `role`<br>\n",
    "> `role` **:** `ai`, `human`, `system`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd3335b7-eff0-442a-92b8-957a0ac65623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0d14e-d326-47bd-9ea2-28a04880a8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c613f359-7549-4d4a-911d-72898b74e603",
   "metadata": {},
   "source": [
    "> way -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b72c816a-8cbc-43b2-92a4-5d895ecafc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_1 = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Your are a helpful AI bot, Your name is {name}'),\n",
    "    ('human', 'Hello, how are you doing?'),\n",
    "    ('ai', \"i'm doing well, thanks!\"),\n",
    "    ('human', \"{user_input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6173be0-4705-4626-98e1-d4e99d219c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Your are a helpful AI bot, Your name is Bob', additional_kwargs={}),\n",
       " HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"i'm doing well, thanks!\", additional_kwargs={}, example=False),\n",
       " HumanMessage(content=\"what's your name?\", additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_1.format_messages(name='Bob', user_input=\"what's your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43d70f-92e0-4f90-9b06-de62d001707e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7f97a81-30b6-42b2-8a1f-da0b55cb6e65",
   "metadata": {},
   "source": [
    "> way -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8443a1-f243-4ff1-929a-fc04125b5516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2074e2bb-9892-40dd-98f6-1e8f701f820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import HumanMessage, AIMessage\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "107652f7-3313-4237-9241-a1fffac638c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_2 = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template('Your are a helpful AI bot, Your name is {name}'),\n",
    "    HumanMessage(content=('Hello, how are you doing?')),\n",
    "    AIMessage(content=(\"i'm doing well, thanks!\")),\n",
    "    HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77e8705f-c712-438b-b250-08d1cfd2d4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Your are a helpful AI bot, Your name is Bob', additional_kwargs={}),\n",
       " HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"i'm doing well, thanks!\", additional_kwargs={}, example=False),\n",
       " HumanMessage(content=\"what's your name\", additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_2.format_messages(name='Bob', user_input=\"what's your name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23022d08-d9c6-409e-9f55-9a726863a66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159ea74-696e-4aa4-864d-c9fd3506dc22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9685f9e-177d-4bab-a2a3-55a193508f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf356df9-6fc2-4c34-ad63-06d692bb663f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd035c47-7fcc-485d-9d8e-1b2bb2bb87b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c37e1-c599-4abf-ae08-38450d9c2d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cfa0c2-3c09-43ee-9833-c5b9e7e0c582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39237691-b470-4866-96ea-f85977b63cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-preventloss-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "Python [conda env:preventloss]",
   "language": "python",
   "name": "conda-env-preventloss-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
