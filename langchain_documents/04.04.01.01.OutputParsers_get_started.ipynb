{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf447e2-977d-4940-98b8-251198ea4455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc1a161-3c9d-4cb2-a0b3-33b496eff06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "193cadcf-066e-4e77-b0ad-6b8639dac290",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2e992-db57-4ea1-892a-d8baa65c7652",
   "metadata": {},
   "source": [
    "**产生的原因: 大模型返回的是str, 而我们希望是结构化的**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac086e3c-ec4d-4114-a276-f0acdf0c8b59",
   "metadata": {},
   "source": [
    "Output parsers are classes that help structure language model responses. There are two main methods an output parser must implement:\n",
    "\n",
    "* **Get format instructions**: A method which returns a string containing instructions for <br>\n",
    "  how the output of a language model should be formatted.<br>\n",
    "* **Parse**: A method which takes in a string (assumed to be the response from a language model)<br>\n",
    "   and parses it into some structure.\n",
    "   \n",
    "* **Parse with prompt** (**Optional**) A method which takes in a string (assumed to be the response from a language model) and a prompt (assumed to be the prompt that generated such a response) and parses it into some structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25594570-f418-4495-a14d-ef3622415a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d45c865-1367-4eaa-a8b7-213c01153c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec176fe-f175-40b7-bd7c-3a2755c898a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94783198-48cd-4fb7-82f6-77e1856f57c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867d95c9-951f-4f58-8ef5-84cbbf7f56a1",
   "metadata": {},
   "source": [
    "### 要素1: OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6d038b-f58f-4688-a535-f31ca0a5c263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define your Desired data structure\n",
    "class Joke(BaseModel):\n",
    "    \n",
    "    setup: str = Field(description='question to set up a joke')\n",
    "    punchline : str = Field(description='answer to resolve the joke')\n",
    "    \n",
    "    # You can add custom validation logic easily with Pydantic\n",
    "    @validator('setup')\n",
    "    def question_ends_with_question_mask(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "    \n",
    "# Set up a parser + inject instructions into the prompt template\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0ecc3-6033-4352-82de-a6f90d5043b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfb474c7-d415-49bc-8ec2-78c07cd94e50",
   "metadata": {},
   "source": [
    "### 要素2 Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa52f3f-a1f8-4d79-8bb9-c2797f9809c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0c8e5a2-e212-4d5b-b079-26eba6bd5474",
   "metadata": {},
   "source": [
    "> You can also just initialize the prompt with the partialed variables 实例化带partial_variables的提示模版\n",
    "\n",
    "> **你也可以在实例化的时候, 部分 格式化Prompt**\n",
    "\n",
    "[Partial Prompt](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8de8e-1038-470f-b8f1-2d1b89b3c72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f84f52c-b28d-4753-8baa-f65dcf02d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915d1b1-43b7-4b39-891d-1de147ed2f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25b5ab9c-e86a-4a56-bba6-b626d38bb232",
   "metadata": {},
   "source": [
    "### 要素3: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f95346-5535-43bd-8ff7-83dda1c3462f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = OpenAI(model_name='text-davinci-003', temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40471fc-d198-4d23-ba6c-ab845b87566a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f0035d-e31b-485c-80e4-e3ab296e585a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "561fd1de-3091-43ac-bd26-5b2a0667c537",
   "metadata": {},
   "source": [
    "### 组合执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db774e71-48fd-4502-acfd-50fe75521ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b0622a-e92d-4a3e-bf3d-7921d57efdf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"query\": \"Tell me a joke.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee59fd9-7c97-4f34-b1bb-d6e8427ff4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "214550a9-ab01-4ce2-bfb9-3a45792a3767",
   "metadata": {},
   "source": [
    "### 分步执行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3bda03-59a5-40f9-817e-531c6df3327b",
   "metadata": {},
   "source": [
    "**\"Get format instructions\": A method which returns a string containing instructions for how the output of a language model should be formatted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6ad797-23df-4834-82f3-871f0ae8992c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157012b7-0a27-4d6a-a343-ef70f7ad6568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede4ec0-5691-4940-8ea1-64e946393bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4bb032-ad5b-495c-aa20-9e14d2aca075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "prompt_and_model = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45aa2f-9d07-4c37-914d-bc702d9847d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7243499b-f684-4e3f-a057-16c3f42b6f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = prompt_and_model.invoke({\"query\": \"Tell me a joke.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e649b-a077-414d-8a21-fe76a1e2f4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0163563b-59eb-48db-825a-b8a916671e12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aeb5c9-5d98-4dc4-a7e8-b39c3721e1e8",
   "metadata": {},
   "source": [
    "**\"Parse\": A method which takes in a string (assumed to be the response from a language model) and parses it into some structure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad1c66fd-6adf-4135-81a3-d9fb0ada3b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee4a17c-ecab-4803-bb91-3c8ffe07f35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd8172-f5d3-40c9-9ab8-39b687aaf74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909dd701-c864-4371-82a5-1bacd3da6d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e044a-dfe7-4e10-9c5f-e2f2277d79dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320c774b-7fb8-476e-9f2e-5ca84de35371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8ebc8d7-74c3-4b60-b2c7-e83fcc9271de",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d836281-8be6-4d7c-b9d1-2a50e564a4da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6036790-749b-4242-8744-efa1a5cbb19e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_prompt = PromptTemplate.from_template(\"Return a JSON object with an `answer` key that answers the following question: {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ea2e190-ee4b-4a44-a901-85fe30961297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_parser = SimpleJsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c06de1d3-a5a4-4827-a4b2-2d880fb52d9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_chain = json_prompt | model | json_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d6a3f14-8cfd-445f-b663-1b3cc5db6412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {'answer': ''},\n",
       " {'answer': 'Ant'},\n",
       " {'answer': 'Anton'},\n",
       " {'answer': 'Antonie'},\n",
       " {'answer': 'Antonie van'},\n",
       " {'answer': 'Antonie van Lee'},\n",
       " {'answer': 'Antonie van Leeu'},\n",
       " {'answer': 'Antonie van Leeuwen'},\n",
       " {'answer': 'Antonie van Leeuwenho'},\n",
       " {'answer': 'Antonie van Leeuwenhoek'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(json_chain.stream({\"question\": \"Who invented the microscope?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe8eed-95ae-46e8-89c9-62f320888488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba9e1792-3ad3-4c2b-b95e-e4d101929359",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chain.stream({\"query\": \"Tell me a joke.\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283e02b-776d-4c4b-9663-5f8adf2c5055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc5d593-f4d3-4ce0-932d-ca341e7b9b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ad8f4-12dd-4284-b22d-ceb7e904763c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-preventloss-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "Python [conda env:preventloss]",
   "language": "python",
   "name": "conda-env-preventloss-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
