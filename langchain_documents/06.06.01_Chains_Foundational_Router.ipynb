{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358df97f-97d9-46fa-a946-159277e34e82",
   "metadata": {},
   "source": [
    "# Router\n",
    "\n",
    "[Routing detail documents](https://python.langchain.com/docs/expression_language/how_to/routing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae0dba6-7557-46af-aac9-c71d0955f9f6",
   "metadata": {},
   "source": [
    "> Routing allows you to create non-deterministic chains where the output of a previous step defines the next step. <br>\n",
    "> Routing helps provide structure and consistency around interactions with LLMs.<br>\n",
    "> `Routing` <font color=blue>允许你创建一个 非确定性 链, 其中上一步的输出定义下一步</font><br>\n",
    "> `Routing` <font color=blue>提供与LLM交互的结构和一致性</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9a51b-dac4-4b2c-b089-5d92de3379e2",
   "metadata": {},
   "source": [
    "> As a very simple example, let's suppose we have two templates optimized for different types of questions, <br>\n",
    "> and we want to choose the template based on the user input.\n",
    "> 我们有两个针对<font color=blue>不同类型问题</font>优化的模板.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce88c1-1d8d-480e-bb1b-565f05854457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f639ce7d-68c1-4778-ad49-ca374e76bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a74333e3-5496-461f-b15c-512000ddf8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba19292-68fd-47b6-a614-3cd6557b788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_prompt = PromptTemplate.from_template(physics_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd52d9-e377-49cd-89a7-8c69fff9842b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418948ff-8b19-4d1d-94cd-3182a6dc569a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe65b44-b85d-429f-98e9-d283fa7e9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06febfbd-6afe-4ebd-b8b4-09fa3e6939b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "math_prompt = PromptTemplate.from_template(math_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae668b-2b55-492a-8f0c-2d6d27dfa295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "462cb0ea-06c8-43b6-8893-fac2e782bf14",
   "metadata": {},
   "source": [
    "## LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b34f7-dfd5-43a5-aea7-9a3c86f7ed62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5917ca55-baf2-4b36-b2d2-f8c242726f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949594df-ba06-49ab-82eb-5eeaefd78f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0c5c16-35f7-41c6-a6cc-313bb1c49789",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_prompt = PromptTemplate.from_template(\n",
    "    \"You are a helpful assistant. Answer the question as accurately as you can.\\n\\n{input}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78d9cf33-9077-434a-9544-7f66993cc6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_branch = RunnableBranch(\n",
    "    (lambda x: x[\"topic\"] == \"math\", math_prompt),\n",
    "    (lambda x: x[\"topic\"] == \"physics\", physics_prompt),\n",
    "    general_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02688f31-f207-406c-99da-cd17c3d61968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa7581d6-5514-4179-9198-0782c3ec4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain.output_parsers.openai_functions import PydanticAttrOutputFunctionsParser\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b4846c-3c75-4663-a820-62542a375b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43a683f8-3aca-4c63-9abd-f663810fda20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TopicClassifier(BaseModel):\n",
    "    \"Classify the topic of the user question\"\n",
    "\n",
    "    topic: Literal[\"math\", \"physics\", \"general\"]\n",
    "    \"The topic of the user question. One of 'math', 'phsyics' or 'general'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef523b5c-2054-4468-9ad0-e92bf71de874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_function = convert_pydantic_to_openai_function(TopicClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfa3cc1b-f545-4061-928b-55b24dbc2bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI().bind(\n",
    "    functions=[classifier_function], function_call={\"name\": \"TopicClassifier\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2af2519-5ad6-40bc-9c68-b7c379df933b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = PydanticAttrOutputFunctionsParser(\n",
    "    pydantic_schema=TopicClassifier, attr_name=\"topic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7334c65-ba86-439f-b569-34fa0992f2d7",
   "metadata": {},
   "source": [
    "### 先用OpenAI 做分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df20bfd6-05a9-4556-853b-ddc1e6bbd27c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_chain = llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b51076-eb49-4617-9f62-76784eac87f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976d579-0124-4a26-beac-d438d2676cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eb86bfe-3e3d-441a-9dbd-9040c334ab62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53ffd065-8d5f-48d6-b395-9be325891ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_chain = (\n",
    "    RunnablePassthrough.assign(topic=itemgetter(\"input\") | classifier_chain)\n",
    "    | prompt_branch\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24db917-2975-40d5-a736-62936302db3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3307b902-f685-4e36-bb43-d22bf99c71e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for your kind words! I'm here to help you with your math question.\\n\\nTo find the first prime number greater than 40, we'll start by listing out prime numbers in ascending order until we find the desired prime number that satisfies the given condition.\\n\\nPrime numbers greater than 40: 41, 43, 47, 53, 59, 61, 67, ...\\n\\nNow, we need to check if one plus each of these prime numbers is divisible by 3. We can do this by calculating the remainder when dividing by 3.\\n\\n(41 + 1) % 3 = 42 % 3 = 0 (divisible by 3)\\n(43 + 1) % 3 = 44 % 3 = 2 (not divisible by 3)\\n(47 + 1) % 3 = 48 % 3 = 0 (divisible by 3)\\n(53 + 1) % 3 = 54 % 3 = 0 (divisible by 3)\\n(59 + 1) % 3 = 60 % 3 = 0 (divisible by 3)\\n(61 + 1) % 3 = 62 % 3 = 2 (not divisible by 3)\\n(67 + 1) % 3 = 68 % 3 = 2 (not divisible by 3)\\n...\\n\\nFrom the above calculations, we can see that the first prime number greater than 40, where one plus the prime number is divisible by 3, is 41. Therefore, the answer is 41.\\n\\nHence, the first prime number greater than 40 such that one plus the prime number is divisible by 3 is 41.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"What is the first prime number greater than 40 such that one plus the prime number is divisible by 3?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad569b-448f-44d7-b87c-057717afd96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa050d-f9c6-4265-b97c-a622f593b005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df7eb87a-c52c-406a-b9bf-a1eed3fd7c8d",
   "metadata": {},
   "source": [
    "### 自定义路由器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60b0ed-7b97-4591-b7f5-a64c024af3e0",
   "metadata": {},
   "source": [
    "```python\n",
    "def route(info):\n",
    "    if \"anthropic\" in info[\"topic\"].lower():\n",
    "        return anthropic_chain\n",
    "    elif \"langchain\" in info[\"topic\"].lower():\n",
    "        return langchain_chain\n",
    "    else:\n",
    "        return general_chain\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5748a66-0f76-46e3-b90d-d2584d5991ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-preventloss-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "Python [conda env:preventloss]",
   "language": "python",
   "name": "conda-env-preventloss-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
