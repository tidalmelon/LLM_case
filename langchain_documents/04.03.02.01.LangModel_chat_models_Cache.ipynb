{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f24ea2-0e97-4f25-a368-a75fc37c693b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8ca7f35-d648-413d-935e-d9aa5cdd0d2d",
   "metadata": {},
   "source": [
    "## Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78363ea6-55d3-46b5-9169-e6cf4840b18c",
   "metadata": {},
   "source": [
    "**前提你有大量的重复请求**\n",
    "1. 缓存同样的请求,减低费用<br>\n",
    "2. 缓存同样的请求,提高速度<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44022c0d-6939-474c-be53-87cef1032ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4934987e-227b-45c5-9a0e-a3770cbcc201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6f4cf-3539-4d66-819f-967bae3fb7ed",
   "metadata": {},
   "source": [
    "### In memory Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24a288a-a9e4-4fab-a250-1d7487507a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233a35f2-d5b2-4ae1-9733-d83b79f2bd38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.29 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sure, here's a classic joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31c2cea-890c-4777-9408-75fcb0a1d36d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here's a classic joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The second time it is, so it goes faster\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a809d4f-b22e-4f60-8b96-6784201e73ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ae026e2-245f-41e0-8ee0-ffbd1daec0d0",
   "metadata": {},
   "source": [
    "### Sqlite cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c25ed9-2859-4e21-9606-47f5301791e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '.langchian.db': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "rm .langchian.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed143cbc-c9c5-40c8-a63d-56e88fc4bbd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path='.langchain.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5c8a9f-c6f8-4796-81f7-c2fe2b506f95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2716fb4-69f2-465c-8e3a-efa6d9481384",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1f69ff-84fe-47d0-9710-3771ceb89c4a",
   "metadata": {},
   "source": [
    "> 返回结果一样,但是时间变小,虽然不明显, 这个可能是Sqlite读取速度的原因"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5e315-d375-40ff-81ca-241c42ba35ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f029725-b5e3-4a67-87c2-11efcae3830f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312644d1-8824-48c0-a44c-97d6abfb4524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45d3d1-9b8f-4feb-9e59-52b8a3618888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34330644-429f-41ca-be70-d533e38ce765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defedae1-e387-41b8-b236-50363317120b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ec563-b1f8-418b-bea2-9039d6adc25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72a37a-c6b5-49e5-a8f5-b92cd7376c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea003e-06c3-472a-a04b-fef1fc1b0111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550e84d-30e1-43c5-8c41-69b4b4aeb858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846adc47-2073-4c66-a935-29e9f3b0a67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3d0a6-ce8c-4c6c-91b5-5539500c3689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb28a5-0c1b-4b74-9590-62f87b4f9c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de509be3-6e67-4d4b-bcfd-36679c0ac6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d282e920-1b59-4fd7-9993-005938df2e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da33c5-9241-4c7a-8c72-d5bff4c5b138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-preventloss-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "chatglm26b",
   "language": "python",
   "name": "chatglm26b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
