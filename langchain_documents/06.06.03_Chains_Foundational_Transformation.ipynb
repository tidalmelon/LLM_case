{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ea7dc-d8a4-49ef-a1df-ddf9208ece5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f936677-74f2-4f8a-8ba9-8e956f5b886c",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00feec5b-c6d2-4845-907f-15e348627d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a52e0a9-cbfe-4703-89e0-20f513e954b5",
   "metadata": {},
   "source": [
    "> Often we want to transform inputs as they are passed from one component to another.<br>\n",
    "> 通常我们想要转变inputs在他从一个组件送到另一个组件的时候"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c590d1-fd3a-4d80-b499-6a6539624b96",
   "metadata": {},
   "source": [
    "> As an example, we will create a dummy transformation that takes in a super long text, filters the text to only the first 3 paragraphs, and then passes that into a chain to summarize those.\n",
    "\n",
    "> 例如，我们将创建一个虚拟转换，它接收超长文本，将文本过滤为仅前 3 段，然后将其传递到链中以总结这些内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf734d-89b3-45ac-9232-2c00a1fd084f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59accf69-39ae-4a58-b852-7d8cc6a94632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Summarize this text:\n",
    "\n",
    "{output_text}\n",
    "\n",
    "Summary:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b951e67-c4dc-4570-b278-6308cc39591e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dce3111-08c8-45b2-8aca-ca4948a539f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./input/state_of_the_union.txt') as f:\n",
    "    state_of_the_union = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf334e84-ee31-41f2-9803-21d4fdb2dbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a889b4f-85cf-4b11-bb1d-25d977178387",
   "metadata": {},
   "source": [
    "## LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc5cf5-6a68-4eb1-bd13-52f12a56b8b3",
   "metadata": {},
   "source": [
    "> With LCEL this is trivial, since we can add functions in any RunnableSequence.<br>\n",
    ">  用LCEL实现很简单, 因为可以为任何RunnableSequence添加函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9748e0-8e80-4ca1-aee5-74c519e6b388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed3fff-7d5b-4ed1-988d-32f67fd7f7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b533bc8-6fde-4fdb-85b4-e528948056cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The speaker addresses the audience, acknowledging the presence of important figures and emphasizing unity among Americans. They mention the impact of COVID-19 and express gratitude for being able to gather again. The speaker emphasizes that, despite political differences, they are united as Americans.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = (\n",
    "    {\"output_text\": lambda text: \"\\n\\n\".join(text.split(\"\\n\\n\")[:3])}\n",
    "    | prompt\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "runnable.invoke(state_of_the_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ef4726-6c8a-458d-80f4-bd9673ef0a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "460660b9-7e51-4cce-bf45-7fc229468c76",
   "metadata": {},
   "source": [
    "## Legacy] TransformationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991a4d57-8367-40c3-881a-c6836fc45421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import TransformChain, LLMChain, SimpleSequentialChain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d36d3-b4a5-41ae-96ee-c212a7d80bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7f1530-8c35-42c2-b968-e20823790ea8",
   "metadata": {},
   "source": [
    "> LCEL的实现显然更简单,仅需要一个字典即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17b482de-2b3e-416b-a569-2b981e345c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_func(inputs: dict) -> dict:\n",
    "    text = inputs[\"text\"]\n",
    "    shortened_text = \"\\n\\n\".join(text.split(\"\\n\\n\")[:3])\n",
    "    return {\"output_text\": shortened_text}\n",
    "\n",
    "\n",
    "transform_chain = TransformChain(\n",
    "    input_variables=[\"text\"], output_variables=[\"output_text\"], transform=transform_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22485920-93e1-438f-9ff5-7ac82b0af0cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Summarize this text:\n",
    "\n",
    "{output_text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"output_text\"], template=template)\n",
    "llm_chain = LLMChain(llm=OpenAI(), prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ba32c5-9ad1-493e-8b22-9621ab8b3cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequential_chain = SimpleSequentialChain(chains=[transform_chain, llm_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1333ca3b-045b-4ee4-b211-fae1aff5b122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In a speech to the nation, the speaker acknowledges the difficulties of the previous year due to COVID-19 and expresses hope for being together again. They emphasize the importance of transcending political divides and uniting as Americans.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_chain.run(state_of_the_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e0f10-3322-4f88-bbff-b959fa63cf45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f5337-da39-4dc7-b00f-d3a137cd2e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db8663-efcc-4ab2-b28c-a4e318d28501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3672920b-15f4-4086-9082-da2743df58f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511046d-8359-4ec1-b4a8-8282942e6af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e287d-0bca-4da4-ba57-eb19f11a353d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb3e9f5-4ae7-4a8a-acf0-5038db3d8611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb1c09-96ee-49b0-ad74-4a2f8ab5b02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b813c3f-5929-43be-8fa7-593b32209b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69b3c1-919e-476f-8e5f-b181a16db50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96d1d0-ce11-46e5-b596-19cecdaeee41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a2316-c721-4710-9ff4-3fdee7e038b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b831b-a6ab-45ca-8c61-0293c08dbdfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073922c-794c-44dc-a256-7a649b5e512c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a805f3-b6c9-4257-8646-e1f3df66c9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4dd205-4a67-4a2d-9de9-117123467905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebe4ea-24d3-4153-9c97-6371aac59c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-preventloss-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "chatglm26b",
   "language": "python",
   "name": "chatglm26b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
