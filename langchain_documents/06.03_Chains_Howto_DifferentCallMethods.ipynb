{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4008cf1-eaac-4e29-8002-c2af13db465e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2bc0806-cd01-42a5-ba48-9d92003b96a7",
   "metadata": {},
   "source": [
    "[Chain How to Chaining](https://python.langchain.com/docs/modules/chains/how_to/call_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7150d9-9377-49b6-addc-2bef56f4735e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a541dd5-6f0f-4569-b7af-bffc980c3dec",
   "metadata": {},
   "source": [
    "## Different Call Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e83474-f1cd-4178-b011-c3962255071d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d056fa2-1cfc-47ed-a1e6-38b05e9db754",
   "metadata": {},
   "source": [
    "> All classes inherited from `Chain` offer a few ways of running chain logic. The most direct one is by using `__call__`:<br>\n",
    "> 只要集成了`Chain`最直接的调用就是`__call__`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5367d7f4-9614-4d55-806e-aaafc904eb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97fe8aad-6ffb-4929-a3ab-319dd98f10b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae7fa76-c7e6-4b9b-bea5-74a0a144ef7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4313034-6962-4a70-aab9-edeed7e3d39a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087b2a1c-8005-4cb3-968e-137f7cef342f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688833f-fbb5-416a-b8d4-87c454369209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d75bbe01-94b8-4bc3-8ff0-ca6fb79a8ab5",
   "metadata": {},
   "source": [
    "> By default, `__call__` returns both **the input and output key values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc7aad-377c-4e58-bde2-f5eec7c6280d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3baf9903-6295-40eb-ad73-19ec8d740985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adjective': 'corny',\n",
       " 'text': \"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(inputs={'adjective': \"corny\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36a5dd-b012-4bf0-a214-07e037be6c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95a81f84-558a-41c5-80a4-2f0612137723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adjective': 'corny',\n",
       " 'text': \"Sure, here's a corny joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"corny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f24dc0-c122-485d-bb4f-6d09c24d9857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2406eac-f1cc-4884-8098-80c045aed3f1",
   "metadata": {},
   "source": [
    "> You can configure it to **only return output key values** by setting `return_only_outputs` to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3386fa88-3335-4c7b-9a02-85e91f78052d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Sure, here's a corny joke for you:\\n\\nWhy don't scientists trust atoms?\\nBecause they make up everything!\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"corny\", return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342959be-7f05-4f09-a330-7636e1c6e628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8568774c-aa4b-457d-bad6-fe701dfa5814",
   "metadata": {},
   "source": [
    "1. 检查LLMChain返回几个**output_keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a693cb-5f5a-4e3a-9466-47cd32aee670",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.output_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb6a88-d32f-4f23-a42d-2ee7cfba3a35",
   "metadata": {},
   "source": [
    "2. If the Chain only outputs one output key. you can use `run` method\n",
    "\n",
    "> <font color=blue>如果仅返回一个output key, 你可以使用**run**方法: 注:放回的是字符串而不是字典</font> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d906ce05-e563-48db-9c31-9f958eb913ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(\"corny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c6a9eee-8e6c-40f8-afd1-c2870841d7eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here's a corny joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run({'adjective': 'corny'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb03cb-58e9-4384-ae42-24db7d615093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bcd751-f9aa-4e63-8535-89b35820ce3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3209a45-283b-4078-b827-56144da19905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5047f1-67db-40b0-86df-d3dcc0213f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a34fe-e97b-487f-86e6-9e6ebf438881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64bd0c2-c6bc-40f8-ba4a-24c86c14f832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba0b5a-7597-4116-8e25-e32ec0ae05bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7958e6-4586-4588-88e6-b73711fb15b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a541d650-1f44-4531-a6f9-6f255be9b52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72596e3-edd7-423f-b395-a54faf27fce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298677a-f8c2-4782-95ad-72145d85fb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aebc84-6e6e-4a41-849b-1abc68115314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb946228-95bf-431e-a92c-390466b5a919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5737b374-f37c-4ee3-ae17-8fd3eaa23819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c30bd2-0d11-4035-abdc-8f66107f95c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a43a1-f393-4e98-ab1c-63fcbbe46a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc418bbc-bf9d-4844-85b2-5b3aa88fa91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4772d-3d7e-4cb5-baa8-7b520678e02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865c90f-dd51-4cd5-bdc8-7aa4efb8540a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db734e2-bf38-4f4d-a2d2-3dada5a8f749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83797891-adbf-41f3-a504-ac15903585a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-preventloss-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "chatglm26b",
   "language": "python",
   "name": "chatglm26b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
