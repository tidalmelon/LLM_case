{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4008cf1-eaac-4e29-8002-c2af13db465e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a680b61-0335-42a6-91fa-1aeccc0402cf",
   "metadata": {},
   "source": [
    "# Foundational LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0becb152-d771-4d32-ab31-746f24a45cac",
   "metadata": {},
   "source": [
    "## Using LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f22a92-a585-454c-b856-b08f1cc4fc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2d1eeb1-302f-474f-b993-ebf915c0ece9",
   "metadata": {},
   "source": [
    "> `BasePromptTemplate`, `BaseLanguageModel` and `BaseOutputParser` all implement the `Runnable` interface and are designed to be piped into one another, making LCEL composition very easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b72bb4f-4fcc-40ac-8b83-b2b1314b5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "842f275c-9620-4235-9589-b073bcfc7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"What is a good name for a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b0da2ea-b7d3-40e0-ae52-d621c041be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | ChatOpenAI() | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6029c6b-6bea-49c8-97a3-fb99110f3937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Colorful Threads'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({'product': 'colorful socks'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79d59b3c-34b8-49a8-96c3-886a57730b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpectrumSock Co."
     ]
    }
   ],
   "source": [
    "for s in runnable.stream({'product': 'colorful socks'}):\n",
    "    print(s, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb26d44-564c-4fe7-9d33-af2e77865d26",
   "metadata": {},
   "source": [
    "## Legacy LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bff4cb-46e6-4e52-b118-eb141c991114",
   "metadata": {},
   "source": [
    "An `LLMChain` consists of a `PromptTemplate` and a language model (either an LLM or chat model).<br>\n",
    "It formats the prompt template using the input key values provided (and also memory key values, if available), passes the formatted string to LLM and returns the LLM output.\n",
    "> 输入键以及内存键 都可以用来格式化提示模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "957c9888-f207-4035-a99f-d416fa3a25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bedbf2e4-dfab-49e2-8696-aebaf76e67a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"What is a good name for a company that makes {product}?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12687b9-4d84-4910-a71f-a905fb831d5a",
   "metadata": {},
   "source": [
    "### \\_\\_call\\_\\_ 返回字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdaaee22-2b69-4484-af25-ec8e7e37ed40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'colorful socks', 'text': '\\n\\nSocktastic!'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "llm_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt_template))\n",
    "llm_chain(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980c5d2-463d-4ef0-8549-d2074eed68b6",
   "metadata": {},
   "source": [
    "### run 返回字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3e8b4ce-aa5d-40a3-b3f2-a48e6589d8ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSocktastic!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "llm_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt_template))\n",
    "llm_chain.run(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa5911e-0738-42cc-8a0e-724cd32fbbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3b0872a-62c9-446c-9469-7bb7cb19409d",
   "metadata": {},
   "source": [
    "### predict 输入k=v,返回字符串\n",
    "\n",
    "predict is similar to run method except that the input keys are specified as keyword arguments instead of a Python dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33c1c687-685a-4bdd-94f7-d239febce2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSocktastic!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single input example\n",
    "llm_chain.predict(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31752f7a-0ebd-4492-bad1-b9c1d39d0788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "348c21e9-068c-43ce-b21f-383f647e2198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nQ: What did the duck say when his friend died?\\nA: Quack, quack, goodbye.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple inputs example\n",
    "template = \"\"\"Tell me a {adjective} joke about {subject}.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"adjective\", \"subject\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=0))\n",
    "\n",
    "llm_chain.predict(adjective=\"sad\", subject=\"ducks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fd6111-7565-42d0-8a0f-9ac5d1f1cd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770fae6d-da3e-4a9d-a8ae-add42e8c3f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7159b85-21ea-47b4-baa2-a017c896fcff",
   "metadata": {},
   "source": [
    "## Additional ways of running LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cdc8e8-a67b-4539-8f21-05d200f4006f",
   "metadata": {},
   "source": [
    "### apply: 多个输入,多个输入,均为字典\n",
    "> **apply allows you run the chain against a list of inputs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35554e48-8dbe-4000-bab4-0385aab219de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\\n\\nSocktastic!'},\n",
       " {'text': '\\n\\nTechCore Solutions.'},\n",
       " {'text': '\\n\\nFootwear Factory.'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [{\"product\": \"socks\"}, {\"product\": \"computer\"}, {\"product\": \"shoes\"}]\n",
    "llm_chain.apply(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18e316-8f7d-4a34-a000-f1392627bb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3777bc18-87b8-4474-b12a-93e10c2f2f08",
   "metadata": {},
   "source": [
    "### generate: 返回LLMResult\n",
    "\n",
    "generate is similar to apply, except it return an `LLMResult` instead of string. LLMResult often contains useful generation such as `token usages` and `finish reason`.\n",
    "> 什么是finish reason ? <br>\n",
    "```python\n",
    "> generation_info={'finish_reason': 'stop', 'logprobs': None}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efb48dce-1309-4211-8513-d6dfa5c3bc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\nSocktastic!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nTechCore Solutions.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nFootwear Factory.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'prompt_tokens': 36, 'completion_tokens': 19, 'total_tokens': 55}, 'model_name': 'text-davinci-003'}, run=[RunInfo(run_id=UUID('216f98dc-bdf1-443a-9e8c-7543275b9f3f')), RunInfo(run_id=UUID('dae879cb-fbe6-4c21-8a6c-f9c7b7943e5a')), RunInfo(run_id=UUID('6f5e2d6b-cd61-4659-a4dc-51539f2d832d'))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.generate(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd50ef8-295c-4f54-be38-3a0cd54f9428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c309650-6979-4855-a3aa-5a6f8bbbf0a3",
   "metadata": {},
   "source": [
    "## Parsing the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13b541-92e5-4421-96ea-b741a65f61cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a32ac84c-7bcb-47cd-881a-013dff54c95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e5396de-5bd1-4312-9195-0b8c17f7329a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "684a6e84-2939-4320-9bbd-7b9dabbb36ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"List all the colors in a rainbow\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38fc1b35-0265-408c-a0d2-644692cede05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=template, input_variables=[], output_parser=output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c38035c-5f98-49aa-8f2a-791d1c15d533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79e7edb6-d949-4a11-9187-eca4f3db33ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRed, orange, yellow, green, blue, indigo, violet'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a441600c-37ee-445e-8b94-b819b996c67c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/preventloss/lib/python3.9/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict_and_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de2944d-14be-4ba9-b9c5-dda0d105200c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c0f04-85b0-401a-9bac-efc421e28478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c783d6e-fc45-4062-a2df-fc9c0a0b1771",
   "metadata": {},
   "source": [
    "## Initialize from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d9d725-96e9-4bbd-9d27-92aaae96a2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eab66fe-65e0-4e6e-ad60-007db8e10e8e",
   "metadata": {},
   "source": [
    "> You can also construct an LLMChain from a string template directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b26a2c5f-8ac7-4227-9849-a4098cc969ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Tell me a {adjective} joke about {subject}.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "384cc4a0-e6e2-4905-a7df-0613175b744f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain.from_string(llm=llm, template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9e40843-c7da-412f-8046-c412b9c6b6fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nQ: What did the duck say when his friend died?\\nA: Quack, quack, goodbye.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(adjective=\"sad\", subject=\"ducks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5614fc-a68e-4caf-a3b6-8de979560291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3b344-1bff-42c8-bd63-c319ce710cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03beeb39-b02c-42d2-9ef2-2bc7d6516ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d8ff82-aa2d-42fd-8196-04790d61c45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c8b74-f38d-4ac0-b5de-151566238588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce88c1-1d8d-480e-bb1b-565f05854457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639ce7d-68c1-4778-ad49-ca374e76bc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c7ef4-8ead-478e-90a4-e38e7a46175e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe65b44-b85d-429f-98e9-d283fa7e9674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148fc0b0-f023-4d23-901e-c57f39f34a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b34f7-dfd5-43a5-aea7-9a3c86f7ed62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5917ca55-baf2-4b36-b2d2-f8c242726f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55095fc2-821a-41e1-b4cb-b98508b1ced3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949594df-ba06-49ab-82eb-5eeaefd78f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0c5c16-35f7-41c6-a6cc-313bb1c49789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d9cf33-9077-434a-9544-7f66993cc6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02688f31-f207-406c-99da-cd17c3d61968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7581d6-5514-4179-9198-0782c3ec4cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-preventloss-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "Python [conda env:preventloss]",
   "language": "python",
   "name": "conda-env-preventloss-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
