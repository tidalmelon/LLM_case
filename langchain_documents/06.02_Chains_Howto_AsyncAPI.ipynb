{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4008cf1-eaac-4e29-8002-c2af13db465e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2bc0806-cd01-42a5-ba48-9d92003b96a7",
   "metadata": {},
   "source": [
    "[Chain How to Chaining](https://python.langchain.com/docs/modules/chains/how_to/async_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7150d9-9377-49b6-addc-2bef56f4735e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "737b8427-2320-4ae1-92ae-76c32836d3ce",
   "metadata": {},
   "source": [
    "## Async API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee02859d-8daf-4420-9b55-fa728f11f821",
   "metadata": {},
   "source": [
    "目前支持异步的有:\n",
    "    \n",
    "1. LLMChain: arun, apredict, acall<br>\n",
    "2. LLMMathChain: arun, acall<br>\n",
    "3. ChatVectorDBChain<br>\n",
    "4. QA Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256335c6-0522-4635-8c56-894f53a010e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2da091-e9fb-4b1f-ad70-5e56923b749e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7886cb64-215b-4c0a-880e-cea00f326254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "110fe9de-d6f6-4db4-b15e-2a26268d4d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_serially():\n",
    "    # 串行生成\n",
    "    llm = OpenAI(temperature=0.9)\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=['product'],\n",
    "        template=\"What is a good name for a company that makes {product}?\",\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    # 运行5遍?\n",
    "    for _ in range(5):\n",
    "        resp = chain.run(product='toothpaste')\n",
    "        print(resp)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71722e12-9ac0-4241-a930-9069c0de2804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17f012c-44a1-40f5-ba76-897264b12b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def async_generate(chain):\n",
    "    resp = await chain.arun(product=\"toothpaste\")\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3a166-4ad6-445e-8345-32f26652b610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9c4de78-46d9-4711-8c2b-86297a677ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def generate_concurrently():\n",
    "    # 并行生成\n",
    "    llm = OpenAI(temperature=0.9)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"product\"],\n",
    "        template=\"What is a good name for a company that makes {product}?\",\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    # 运行5遍\n",
    "    tasks = [async_generate(chain) for _ in range(5)]\n",
    "    await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7e307-52d4-44e2-9d0c-409b6233d1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaee0bb-fa91-42a2-9e48-cee06d24fcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c8fb37-5892-4cad-94d0-0cc85aab47f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b98121-045e-4919-8d06-2b1ffa20bd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # If running this outside of Jupyter, use asyncio.run(generate_concurrently())\n",
    "# await generate_concurrently()\n",
    "# elapsed = time.perf_counter() - s\n",
    "# print(\"\\033[1m\" + f\"Concurrent executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f332d9d2-6462-44b1-b5f2-7cc437dbb740",
   "metadata": {},
   "source": [
    "> 由于未付钱,因此无并非能力,so stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757d2e8-c04a-4b43-a990-2cd15be5fea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a57cc8-13df-46eb-b0ee-4a35cbd6cb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1d5af-7ed2-4c22-85b5-f123b35e8b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff75580b-ac92-4f3e-a5a8-076deeaa4498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s = time.perf_counter()\n",
    "# generate_serially()\n",
    "# elapsed = time.perf_counter() - s\n",
    "# print(\"\\033[1m\" + f\"Serial executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64669cc-b2fb-49c1-b666-2c70379a1894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f4deb-7ac0-45b1-8019-2617fa187c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b79afe-3a86-41d1-b7e6-1da1f5eea954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34328bd2-7a55-4513-a11e-0f897b326e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80202ec5-2fa1-436b-ab18-a50a9b7a1273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e83474-f1cd-4178-b011-c3962255071d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b94ed-10d3-4054-a8a0-5abdad3afcae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-preventloss-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "chatglm26b",
   "language": "python",
   "name": "chatglm26b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
