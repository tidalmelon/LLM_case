{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e851c63-fbb9-4f99-a92b-26dce2e719a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=./imgs/model_io.jpg width=35% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47454cdf-1217-4fbf-a015-5c981b69e2f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "[langchain documents](https://python.langchain.com/docs/modules/model_io/models/chat/llm_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2806292-4cf0-40eb-9f66-941d282dfab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07b77b43-6e8c-4c03-b08f-ad9c273aaa96",
   "metadata": {},
   "source": [
    "[LangChain-Tutorials](https://github.com/sugarforever/LangChain-Tutorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae4b5d-6079-4ccb-9010-fa84c74919e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1988c104-f3d3-478c-8717-5970120214fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c9cffe2-dfe0-440e-a97d-3f42d06e0268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828bc27e-7e3f-4e98-8ed2-185cd4c7daa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a16fc75-2c67-4776-b041-3b5f0dbd85fd",
   "metadata": {},
   "source": [
    "# Few shot examples for chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2f41b-ba1e-423a-95fb-20edd68661bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "929210cf-17f1-474d-9b88-cd3d3074509c",
   "metadata": {},
   "source": [
    "> the optimal prompt compilation will likely vary by model.<br>\n",
    "> 最佳的提示会因模型差异巨大， 为了**规避**这种差异<br>\n",
    "> 因此我们提供了`FewShotChatMessagePromptTemplate`, 它灵活， 可以根据需要修改。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28059f7b-f623-4b8b-9bf1-2ec2452bcc7e",
   "metadata": {},
   "source": [
    "> few shot template模版的目标是动态的根据输入选择样例（比如根据input 与 样例的相似度），<br>\n",
    "> 并在最终提供给模型的Prompt中格式化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22517d0-b63f-4387-b548-9dd83bb385f7",
   "metadata": {},
   "source": [
    "> **Note**: The following code examples are for chat models. For similar few-shot prompt examples for completion models (LLMs), see the few-shot prompt templates guide.<br>\n",
    "> **注意：** 本notebook使用ChatCompletion模型， 04.01.04是基于Completion<br>\n",
    "> 上一节，并没有使用Completion模型啊， 难道是为Completion模型准备的？ `Completion`, `ChatCompletion`的输入不一样？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83729c0a-8dc5-446a-832f-c55271c42cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc0c04-7ca8-4143-8fbc-9ee1028c6386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b428e-256b-4c1d-af04-5199cd751363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17b18587-d1c6-4c56-911f-ffd0cc476d41",
   "metadata": {},
   "source": [
    "## 一: Fixed Example\n",
    "\n",
    "> 最简单的固定的提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bb05c-df8e-470f-910c-be0d0dcf2759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2cd8635-e626-46ce-bfc8-93cd5f0ea373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04c75f4-fca1-450b-a2fc-14263795f70e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Sequence[MessageLikeRepresentation]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'ChatPromptTemplate'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Create a chat prompt template from a variety of message formats.\n",
       "\n",
       "Examples:\n",
       "\n",
       "    Instantiation from a list of message templates:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        template = ChatPromptTemplate.from_messages([\n",
       "            (\"human\", \"Hello, how are you?\"),\n",
       "            (\"ai\", \"I'm doing well, thanks!\"),\n",
       "            (\"human\", \"That's good to hear.\"),\n",
       "        ])\n",
       "\n",
       "    Instantiation from mixed message formats:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        template = ChatPromptTemplate.from_messages([\n",
       "            SystemMessage(content=\"hello\"),\n",
       "            (\"human\", \"Hello, how are you?\"),\n",
       "        ])\n",
       "\n",
       "Args:\n",
       "    messages: sequence of message representations.\n",
       "          A message can be represented using the following formats:\n",
       "          (1) BaseMessagePromptTemplate, (2) BaseMessage, (3) 2-tuple of\n",
       "          (message type, template); e.g., (\"human\", \"{user_input}\"),\n",
       "          (4) 2-tuple of (message class, template), (4) a string which is\n",
       "          shorthand for (\"human\", template); e.g., \"{user_input}\"\n",
       "\n",
       "Returns:\n",
       "    a chat prompt template\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/envs/preventloss/lib/python3.9/site-packages/langchain/prompts/chat.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ChatPromptTemplate.from_messages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa8b06-b3bd-492f-9b16-e8ab9eafc8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fe6c1f2-92e9-42ba-b682-9f4f2bce9b89",
   "metadata": {
    "tags": []
   },
   "source": [
    "> **提示模版的基本组件包含2个：**<br>\n",
    "> `example`: dictionary examples组成的数组<br>\n",
    "> `example_prompt`: **将每个example转为message**convets each example into 1 or more messages throught its `format_messages` method. <br>\n",
    ">> A common example would be to convert each example into one human message and one AI message, or a human message followed by a function call message.<br>\n",
    ">> 一个普通的示例是将每一个样例转换成一个human message和一个AI message响应。 或者 一个human message 紧跟着一个回调函数message。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e11761-41aa-4854-895f-0fcf9c92e414",
   "metadata": {},
   "source": [
    "> 1. 定义你要包含的参数`examples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00642e5-8a13-4f2f-902e-4ced321216cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaad3e1-ba1d-4cde-85ca-0208ce1a1ca1",
   "metadata": {},
   "source": [
    "> 2. 定义`example_prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d52f14-8ac0-4037-a035-375ec2c05dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input', 'output'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='{input}', template_format='f-string', validate_template=True), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], output_parser=None, partial_variables={}, template='{output}', template_format='f-string', validate_template=True), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a prompt template used to format each individual example.\n",
    "# 这是一个prompt template 用来格式化每一个独立的example\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('human', '{input}'),\n",
    "        ('ai', '{output}')\n",
    "    ]\n",
    ")\n",
    "example_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9082ac9e-3b79-4e36-887b-4fbd1381a353",
   "metadata": {},
   "source": [
    "> 3. assemble上述参数到`FewShotChatMessagePromptTemplate`<br>\n",
    "> **注意Prompt是层层递进的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e1a746c-51a3-4347-a5e9-1307b496db1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(example_prompt=example_prompt, examples=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b6d1b2-87ee-4365-94f9-e6455def5200",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 2+2\n",
      "AI: 4\n",
      "Human: 2+3\n",
      "AI: 5\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081e4959-8c17-408a-ab8f-5595d5d311a6",
   "metadata": {},
   "source": [
    "> 4. 组装最终的提示，并用于模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2800386a-1cae-4756-a1fe-9a178926e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', \"You are wonderous wizard of math.\"),\n",
    "        few_shot_prompt,\n",
    "        ('human', \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1363e3-d172-4510-8acd-66cb66be4b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1da9a7db-1e6c-44e0-8abc-6467dc3da1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8766cf4b-1a87-49c1-ae16-94abd91dbe01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=ChatOpenAI(),\n",
    "                 prompt=final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501aca90-a09f-418a-bf6d-bb02c8b6e530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5373934a-02c2-448a-81ee-ca93ba28d236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A triangle does not have a square. The square is a shape with four equal sides and four right angles, while a triangle has three sides and three angles. However, you can find the area of a triangle using the formula: \\nArea = (base * height) / 2.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run({\"input\": \"What's the square of a triangle?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aab12bf6-d235-4231-a1e0-bd6bb9f16b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the square of a triangle?\",\n",
       " 'text': 'A triangle does not have a square because a square is a four-sided polygon with equal sides and angles, while a triangle has three sides and three angles. However, the area of a triangle can be calculated using the formula: (base x height) / 2.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What's the square of a triangle?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6505a40-bcfa-4695-b979-53840ac6d482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cef7d11-fa27-43d9-8b7b-b4ae5da5b3db",
   "metadata": {},
   "source": [
    "## 二: Dynamic Few-shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f5c98-04c7-417d-9349-86b315c3a38e",
   "metadata": {},
   "source": [
    "> **有时候你希望根据你的输入选择few shot example:** <br>\n",
    "> `example_selector`: 例如基于vector store的语义相似度`SemanticSimilarityExampleSelector` <br>\n",
    "> `example_prompt`: **将每个example 转为 1到多个message, 同上**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0827e9a8-0e3f-4c02-9ece-a91e8e55929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import SemanticSimilarityExampleSelector\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "968ffc77-1628-4711-b090-a557a412affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
    "    {\"input\": \"2+4\", \"output\": \"6\"},\n",
    "    {\"input\": \"What did the cow say to the moon?\", \"output\": 'nothing at all'},\n",
    "    {\n",
    "        'input': 'Write me a poem about the moon',\n",
    "        'output': \"One for the moon, and one for me, who are we to talk about moon?\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f499fed-1ef8-44f9-b8d0-bf35df1384c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vectorize = [' '.join(example.values()) for example in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e70074d4-7914-40a8-b2de-dbfda3dbfcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2+2 4',\n",
       " '2+3 5',\n",
       " '2+4 6',\n",
       " 'What did the cow say to the moon? nothing at all',\n",
       " 'Write me a poem about the moon One for the moon, and one for me, who are we to talk about moon?']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a03a671-f0d4-4d41-84c9-946ba7297955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ad27555-6e3c-410f-b066-f2a3c41f7d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad4c53-7c82-4d95-a633-b6b0e243b40c",
   "metadata": {},
   "source": [
    "### create the `example_selector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b934cbeb-50c8-41b9-962b-109e2be8a2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore,\n",
    "    k=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "041c01aa-8ca3-441d-8239-3612debbc182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'What did the cow say to the moon?', 'output': 'nothing at all'},\n",
       " {'input': '2+4', 'output': '6'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the prompt template will load examples by passing the input do the `select_exampes` method\n",
    "example_selector.select_examples({'input': 'horse'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad566b-2c8e-42bd-9a6e-e2bdb45e7322",
   "metadata": {},
   "source": [
    "> 确实 马 和牛挺相近的。<br>\n",
    "> 2+4 6 也和马相似？  i dont think so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a1b5b3-6d72-46fa-91f4-81ba5a852304",
   "metadata": {},
   "source": [
    "### create prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cbc2a30a-641d-4c51-b0a1-377d0d8e708b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69194d79-9693-4153-b4db-5bf17d24637d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca101d90-32d6-4924-aa91-dd6b0e6906f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the few-shot prompt\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(input_variables=['input'], \n",
    "                                                   example_selector=example_selector,\n",
    "                                                   # define how each example will be fromatted.\n",
    "                                                   # In this case, each example will become 2 message:\n",
    "                                                   # 1 human, and 1 AI\n",
    "                                                   example_prompt=ChatPromptTemplate.from_messages([('human', '{input}'), ('ai', '{output}')])\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103cf1f2-3a93-4495-9e92-414ea8bc02c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d920f1a1-e751-446b-a610-ef98510f6cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 2+3\n",
      "AI: 5\n",
      "Human: 2+2\n",
      "AI: 4\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input=\"what's 3+3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb971f5-8d93-49ef-ba99-2b71326b997a",
   "metadata": {
    "tags": []
   },
   "source": [
    "> 2+4的相似度小于  2+2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc2614c4-64d0-48ce-a6e6-946df20321f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'You are wonderous wizard of man.'), \n",
    "        few_shot_prompt,\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef89cc8a-473a-464f-84a8-e7a9dab6ee9b",
   "metadata": {},
   "source": [
    "### use with An LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b9ff0d2-f42b-48a4-ac49-117c9e49b0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32204375-225b-463d-a480-558ed950fae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=ChatOpenAI(), prompt=final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07acf2c5-0fb6-40ef-87d3-86a86d8f511e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"what's 3+3\", 'text': '3 + 3 equals 6.'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = chain.invoke({\"input\": \"what's 3+3\"})\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "80020011-f63f-44d6-a861-01a39ec5fec6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0f9cd-ffa0-4ac7-a784-2bae478c6558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-preventloss-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "lglm",
   "language": "python",
   "name": "lglm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
