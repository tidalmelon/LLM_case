{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e851c63-fbb9-4f99-a92b-26dce2e719a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=./imgs/model_io.jpg width=35% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47454cdf-1217-4fbf-a015-5c981b69e2f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "[langchain documents](https://python.langchain.com/docs/modules/model_io/models/chat/llm_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2806292-4cf0-40eb-9f66-941d282dfab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07b77b43-6e8c-4c03-b08f-ad9c273aaa96",
   "metadata": {},
   "source": [
    "[LangChain-Tutorials](https://github.com/sugarforever/LangChain-Tutorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700f1574-f119-4e8d-bea8-96c9c06b9516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06346c2d-36d3-47dd-992b-404d25663045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '************'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83793f12-324e-4bf7-ab92-5b9f604e9e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d25e7a-60bc-49fb-91d8-35c22636eb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec425169-5188-4b11-a150-f7501fb3a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PromptTemplate(input_variables=['topic', 'language'], output_parser=None, partial_variables={}, template='Tell me a joke about {topic}, make it funny\\n\\nand in {language} ', template_format='f-string', validate_template=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625fd4b8-a831-4453-878a-f5a3fe32c003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc8b0f4-5efd-4d63-baf8-f7edcca94296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7acc4f1e-312c-4824-9192-25d27c650c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mPromptTemplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput_variables\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_parser\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseOutputParser\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpartial_variables\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtemplate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtemplate_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'f-string'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidate_template\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A prompt template for a language model.\n",
       "\n",
       "A prompt template consists of a string template. It accepts a set of parameters\n",
       "from the user that can be used to generate a prompt for a language model.\n",
       "\n",
       "The template can be formatted using either f-strings (default) or jinja2 syntax.\n",
       "\n",
       "Example:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        from langchain import PromptTemplate\n",
       "\n",
       "        # Instantiation using from_template (recommended)\n",
       "        prompt = PromptTemplate.from_template(\"Say {foo}\")\n",
       "        prompt.format(foo=\"bar\")\n",
       "\n",
       "        # Instantiation using initializer\n",
       "        prompt = PromptTemplate(input_variables=[\"foo\"], template=\"Say {foo}\")\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Create a new model by parsing and validating input data from keyword arguments.\n",
       "\n",
       "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/envs/preventloss/lib/python3.9/site-packages/langchain/prompts/prompt.py\n",
       "\u001b[0;31mType:\u001b[0m           ModelMetaclass\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PromptTemplate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3777118-1fe6-40ab-b29b-89b7d571484a",
   "metadata": {},
   "source": [
    "> **validate_template is True.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3813e710-cba9-4c76-bb9b-f2fa19778ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97277a4e-c83f-4491-a774-2f0fd02dd8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b857ff-345f-498b-acd4-a9d8ee9257bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"I am learning langchain because {reason}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80edfb1f-b1d7-4fa7-8557-e5c9f9c781c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for PromptTemplate\n__root__\n  Invalid prompt schema; check for mismatched or missing input parameters. {'foo'} (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m \u001b[43mPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreason\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# ValueError due to extra variables\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/preventloss/lib/python3.9/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m/opt/conda/envs/preventloss/lib/python3.9/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for PromptTemplate\n__root__\n  Invalid prompt schema; check for mismatched or missing input parameters. {'foo'} (type=value_error)"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(template=template,\n",
    "                                 input_variables=[\"reason\", \"foo\"]) # ValueError due to extra variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5feed3-fc8f-470b-a34a-7c379f070211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "642befbe-b69f-413b-ad7a-ce337359f56a",
   "metadata": {},
   "source": [
    "> no err:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59034710-2141-42ce-99dd-bb214bf47bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(template=template,\n",
    "                                 input_variables=[\"reason\", \"foo\"],\n",
    "                                 validate_template=False) # No error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55875b-7049-42fa-a933-de1ff1233ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-preventloss-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "lglm",
   "language": "python",
   "name": "lglm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
