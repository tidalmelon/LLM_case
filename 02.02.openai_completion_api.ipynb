{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac72cd6-78aa-43c0-841b-dc3794611a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44cfbe92-998c-4f6b-a488-8c4039d6a158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Creates a new completion for the provided prompt and parameters.\n",
       "\n",
       "See https://platform.openai.com/docs/api-reference/completions/create for a list\n",
       "of valid parameters.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/nlp/lib/python3.9/site-packages/openai/api_resources/completion.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "openai.Completion.create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e231a1-818d-41d0-81c7-2361afff3f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "278cb0d7-08c8-4f51-9c2e-7d6a1831e8b9",
   "metadata": {},
   "source": [
    "## model\n",
    "\n",
    "最重要的两个参数<br>\n",
    "\n",
    "* temperature\n",
    "\n",
    "* presence_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cee12e-eb6f-476a-815b-e915823343f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "733d0b46-dab5-41e2-95a1-f3ce88252143",
   "metadata": {},
   "source": [
    "> 必选参数.<br>\n",
    "> 可以调用的模型包括:<br>\n",
    ">> `text-davinci-003`, `text-davinci-002`, `text-curie`, `text-babbage-001`, `text-ada-001`<br>\n",
    ">> OpenAi提供的ABCD四大模型，参数越多效果越好，价格越贵<br>\n",
    ">> 一般选用参数最大的: `text-davinci-003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe391c01-a203-4706-b33f-e8b60e632ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "616fbc5b-376a-4065-b83c-4ca49b5f939c",
   "metadata": {},
   "source": [
    "> prompt 必选参数，提示词<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc75b22f-2beb-46f2-ae75-cffc4c76a301",
   "metadata": {},
   "source": [
    "> suffix: 可选参数，默认空，模型返回结果的后缀。举个例子，礼貌用语.`预祝商祺`, `生活愉快`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8725852-f1a5-4c45-821b-f4872c8c13c8",
   "metadata": {},
   "source": [
    "> max_tokens: \n",
    ">> 可选参数， 默认16， 代表返回结果的token数量.<br>\n",
    ">> 16一般是不够的。 <font color=green>200左右比较合理</font><br>\n",
    ">> 当然这取决于经费, 及你想要返回多少.<font color=green>是按照token付费的</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377da761-e342-47a9-a0a4-b647e0d0ae73",
   "metadata": {},
   "source": [
    "> **temperature**: <br>\n",
    ">> 可选参数, 范围0-2, 默认1. <font color=green> 在中间，top_p默认值是最大值  </font> <br>\n",
    ">> 参数代表温度<br>\n",
    ">> 数值越小，模型倾向于高概率词汇. 文本更保守, 更加严谨， 更加严肃<br>\n",
    ">> 数值越大，模型倾向于低概率词汇. 文本更多样， 更活泼，甚至胡说八道<br>\n",
    ">> 对应着预设聊天机器人的风格： 严谨的， 平衡的， 生动有趣的<br>\n",
    "\n",
    ">> 此参数核心目的：使用大模型是为了激发某一方面的涌现能力。 <br>\n",
    ">> <font color=green>设为0，一些激发`涌现能力`的措施（比如 提示技巧）可能失效。</font> <br>\n",
    ">> <font color=green>温度高一些，提高模型`涌现能力的技巧(措施)`表现越好。热糊涂了</font>\n",
    "\n",
    "> top_p: <br>\n",
    ">> 可选参数, 取值范围0-1,默认值为1.<br>\n",
    ">> 用于控制文本的随机性, <font color=green>趋近于0，随机性越弱. 趋近于1，随机性越强.</font><br>\n",
    ">> 调节随机性temperature，和top_p二选一即可，<font color=green>一般推荐temperature. 因为调整temperature会对结果又非常大的影响，top_p则不会</font>\n",
    "\n",
    ">> top_p参数的深度解释:<br>\n",
    ">> 这个参数叫做<font color=green>p采样, nucleus采样</font>.<br>\n",
    ">> top是一种在LLM生成文本时常用的采样策略参数，特别是GPT模型（例如GPT-2或GPT-3）时。<br>\n",
    ">> <font color=green>生成文本时, 模型会为下一个词预测一个概率分布， 然后我们可以从这个分布中采样一个词。</font><br>\n",
    ">> **p采样**定义了一个**概率阈值**，用来确定哪些词被包括在nucleus中, 例如：top_p设置为0.9，那么就会选择概率最高的词，直到这些词的累积概率达到或者超过0.9，然后从这些词中随机选择下一个词.<br>\n",
    ">> **p采样**的优势在于，语言模型生成下一个词表的概率是长尾分布，很少的词占据了大部分的概率。动态的调整了需要考虑的词的数量（top_k太硬）， 从而增强了生成文本的多样性，同时还兼顾了一定的连贯性和质量<br>\n",
    "\n",
    ">> top_p接近1，更多的词被包括在采样的`nucleus`（这些词累积概率超过top_p）中，因此模型生成的文本会有更高的随机性,选择空间更大, 如果=1就是`vocab_size`, 随机性更大, 多样性增高，连贯性降低。<br>\n",
    ">> top_p接近0，很少的词包括在`nucleus`中，模型会选择可能性最高的词，确定性更高，多样性低，连贯性高<br>\n",
    ">> <font color=green>我们需要再随机性和确定性之间权衡</font><br>\n",
    ">> <font color=green>取到一个合适的top_p可能需要一些实验，这取决于具体的应用</font><br>\n",
    ">> <font color=green>和对输出文本多样性和连贯性的期望</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a49b5-2ba0-483b-a109-bc604e1dc43b",
   "metadata": {},
   "source": [
    "> n, 可选参数，默认值为1，表示提示返回几个completion.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bf4097-a6b6-4045-9c12-07338bf38ba1",
   "metadata": {},
   "source": [
    "> stream: 可选参数，默认值为False，生成所有文字后一起返回。stream=True, 则生成一个返回一个。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24f509-7173-4308-8009-31997df90150",
   "metadata": {},
   "source": [
    "> logprobs, 可选参数，默认值为null<br>\n",
    ">> 设置logprobs=10，<font color=green>那么对于生成的每个token，API会返回模型预测的前10个token及其概率</font><br>\n",
    ">> 我们一般不修正结果， 因此此参数一般不使用<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e41804-aba9-4717-b84f-e01657dd319d",
   "metadata": {},
   "source": [
    "> echo, 回音. 默认False<br>\n",
    ">> 如果设置为True，模型响应会尽可能的复述用户的输入<br>\n",
    ">> 输入什么，就返回什么<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b69cda-dfeb-47c8-be76-45ea04fd393b",
   "metadata": {},
   "source": [
    "> stop, 默认null<br>\n",
    ">> 如果模型在创作时生成了stop指定的词，则提前结束<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4545689b-8341-4286-b866-8979826ca83c",
   "metadata": {},
   "source": [
    "> **presence_penalty**, 可选参数，默认为0中间值, 取值范围[-2, 2], <font color=green>惩罚主题重复度, **此参数很重要**</font><br>\n",
    ">> 用于调整模型生成新内容（例如新的概念和<font color=green>主题</font>）的倾向性。<br>\n",
    ">> 较高的值会使模型更倾向于生成<font color=green>新内容</font>, 而<font color=green>较低的值会使模型倾向于坚持已有的内容</font><br>\n",
    ">> <font color=green>**当返回结果篇幅较大**并且存在前后主题重复时，可以提高该参数的值</font><br>\n",
    "\n",
    ">> 提升temperature, 降低penalty，会提升模型创造力<br>\n",
    ">> 降低temperature，提升penalty，会言简意赅<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6adae-7993-4d05-baa4-20cc90f16989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09de7225-6739-4bbb-8f02-d259599e1b53",
   "metadata": {},
   "source": [
    "> frequency_penalty, 可选参数， 默认0中间值，取值范围[-2,2] <font color=green>惩罚相同词汇重复度</font>\n",
    ">> 较高时， 对前后出现重复词汇的惩罚就越高，则越不会出现重复词汇<br>\n",
    ">> <font color=green>主题大于词汇，所以一般调整presence_penalty</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba40f515-0596-42c7-9c9b-b452d690b4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46c2158f-bc51-4588-ba58-e6550b2ef00c",
   "metadata": {},
   "source": [
    "> best_of:  默认值为 1, <font color=green>这个参数很重要</font><br> \n",
    ">> 例如best_of = 5, 则先创建5组答案，然后选择reponse中<font color=green>得分最高的一个(束搜索 维特比解码)</font>.<br>\n",
    ">> <font size=4 color=green>如果n=2， best_of=5, 则会为每一个n生成5个响应，再为每个n自动选择一个最好的响应返回。即生成了10个响应</font>\n",
    ">> <font color=green size=3>钱的消耗量更大一些</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83defd13-3384-446a-93a7-a1d75b45ade5",
   "metadata": {},
   "source": [
    "> logit_bias: 手动调整概率，调整生成结果<br>\n",
    ">> 接受一个字典，字典的key是token的ID，用于调整特定token的概率。value是应用于<font>该token的对数概率的偏置</font><br>\n",
    ">> GPT中我们可以使用tokenizer tool查看Token的标记。<font color=green>一般不建议修改: 你调整的那几个单词，对如此大规模参数的模型来说基本没有影响</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f1aff3-3353-46fd-b12d-9a546f850903",
   "metadata": {},
   "source": [
    "> user: 可选参数.<br>\n",
    ">> 注明当前使用者身份。提问的是A用户，提问的是B用户, 对于completion没用<br>\n",
    ">> <font color=green>但对ChatCompletion模型的User，会用来定位身份，根据不同的身份提供不同风格的对话。</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7d274-49e4-4ef0-a4c5-b2be59adcd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7049b-4e15-476b-bdf1-39913a70f887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e15d6-5e33-41e6-8912-72f5ab013270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60980ec0-0afd-49b6-8eeb-55c2a500d329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566f80d-d3e7-4bb5-a9ab-1f53016cd985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ccb0f-29fb-4a30-9b42-bf1481039fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-preventloss-py",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "lglm",
   "language": "python",
   "name": "lglm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
