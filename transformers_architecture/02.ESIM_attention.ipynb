{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a8a420-360f-489a-b6c5-a12715981dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Esim中的：注意力机制\n",
    "$$\\large \\rm e_{ij} = {\\overline p_i}^T {\\overline q}_j $$\n",
    "\n",
    "\n",
    "||爱|打|篮|球||\n",
    "|---|---|---|---|---|---|\n",
    "|喜|score0|score1|score2|score3|\\|step1:score0 = 喜的embedding 与 爱的embedding内积(内积=相似度=未归一化的余弦相似度)|\n",
    "|欢|||||\\|step2:score0-score4 进过softmax变成p0-p3, p0+p1+p2+p3=1|\n",
    "|打|||||\\|step3:喜_hat = 爱embeding\\*p0 + 打embedding\\*p1 + 篮embedding\\*p2 + 球embedding\\*p3|\n",
    "|篮|||||\\|即：喜_hat = 喜 与 '爱打篮球‘每个词的相似度的加权平均|\n",
    "|球|||||\\|key point： 注意力机制是词粒度的, 注意力要实现的是语义对齐。（跟词的embedding无关)|\n",
    "\n",
    "\n",
    "$$\\large \\rm {\\overline  p}_i  = \\sum_{j=1}^{l_q}  \\frac{exp(e_{ij})}{\\sum_{k=1}^{l_q} exp(e_{ij})} {\\overline q}_j, \\forall_i \\in [1, \\cdots, l_p]$$\n",
    "\n",
    "\n",
    "$$\\large \\rm {\\overline  q}_i = \\sum_{j=1}^{l_p}  \\frac{exp(e_{ij})}{\\sum_{k=1}^{l_p} exp(e_{ij})} {\\overline p}_i, \\forall_i \\in [1, \\cdots, l_q]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7dac5e7-69dd-40c7-9dfd-44b30cf16f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3158577b-2225-4308-b127-0116fb88b288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cu111'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d67f78-9e5f-4dd2-b082-c1a0ba11282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载停用词\n",
    "def load_stop_words():\n",
    "    stop_words = set([])\n",
    "    fname = './data/stopwords.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            stop_words.add(line)\n",
    "    return stop_words   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "826710c9-e143-4a22-a6b3-9586ac28f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = load_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7348746-2aa5-489a-8a13-61962cca669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [word for word in jieba.cut(text) if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdff4fa0-a9a8-4678-9f5e-680946d1d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "def split_data(df, split=0.7):\n",
    "    df = df.sample(frac=1)\n",
    "    length = len(df)\n",
    "    train_data = df[0:length - 5000]\n",
    "    eval_data = df[length - 5000:]\n",
    "\n",
    "    return train_data, eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef85715-a5dd-4308-b39f-ecf47de742b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把数据转换成index\n",
    "def seq2index(seq):\n",
    "    seg = tokenize(seq)\n",
    "    seg_index = []\n",
    "    for s in seg:\n",
    "        seg_index.append(vocab.get(s, 1))\n",
    "    return seg_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b720fb5f-8b0c-4931-b7e3-41b7e0a7e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建词典\n",
    "def build_vocab(del_word_frequency):\n",
    "    data = pd.read_csv('./data/LCQMC.csv')\n",
    "    segment1 = data['sentence1'].apply(tokenize)\n",
    "    segment2 = data['sentence2'].apply(tokenize)\n",
    "    \n",
    "\n",
    "    word_frequency = defaultdict(int)\n",
    "    for row in segment1:\n",
    "        for i in row:\n",
    "            word_frequency[i] += 1\n",
    "    for row in segment2:\n",
    "        for i in row:\n",
    "            word_frequency[i] += 1\n",
    "    \n",
    "    word_sort = sorted(word_frequency.items(), key=lambda x: x[1], reverse=True)  # 根据词频降序排序\n",
    "\n",
    "    f = open('./data/vocab_esim.txt', 'w', encoding='utf-8')\n",
    "    f.write('[PAD]' + \"\\n\" + '[UNK]' + \"\\n\")\n",
    "    for d in word_sort:\n",
    "        if d[1] > del_word_frequency:\n",
    "            f.write(d[0] + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10f8c7a1-ccd6-463d-a4a3-9adfdd5af466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.386 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "build_vocab(del_word_frequency=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d2b3933-74eb-46b5-9b97-922b8628eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "import os\n",
    "if os.path.exists('./data/vocab_esim.txt'):\n",
    "    with open('./data/vocab_esim.txt', encoding='utf-8')as file:\n",
    "        for line in file.readlines():\n",
    "            vocab[line.strip()] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2313696-9e68-430e-8641-021f13dc87a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22429"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4dcada-451a-487f-9fa8-9360f5204646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "185ee79c-eac6-4acc-976c-1d64f2a57cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESIM(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, char_dim, char_hidden_size, max_len):\n",
    "        super(ESIM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, char_dim)\n",
    "        \n",
    "        # [batch_size, seq_len, hidden_size]\n",
    "        # 期望[seq_len, batch_size, hidden_size]\n",
    "        self.char_lstm = nn.LSTM(input_size=char_dim, \n",
    "                                hidden_size=char_hidden_size, \n",
    "                                num_layers=1,\n",
    "                                bidirectional=True,\n",
    "                                batch_first=True)\n",
    "                                # drop_out=0.4) 在这里drop_out也是一样的, 两种方式都可以\n",
    "        \n",
    "        self.context_lstm = nn.LSTM(input_size=2*char_hidden_size*4,\n",
    "                                   hidden_size=char_hidden_size,\n",
    "                                   num_layers=1,\n",
    "                                   bidirectional=True,\n",
    "                                   batch_first=True)\n",
    "        \n",
    "        \n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=(max_len, 1))\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=char_hidden_size*2*4, \n",
    "                             out_features=char_hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features=char_hidden_size, out_features=1)\n",
    "        \n",
    "        self.drop_out = nn.Dropout(0.4)\n",
    "       \n",
    "    \n",
    "    def forward(self, char_p, char_q):\n",
    "        # input encoding\n",
    "        embedding_p = self.embedding(char_p)\n",
    "        embedding_q = self.embedding(char_q)\n",
    "        \n",
    "        lstm_p, _ = self.char_lstm(embedding_p)\n",
    "        lstm_q, _ = self.char_lstm(embedding_q)\n",
    "        lstm_p = self.drop_out(lstm_p)\n",
    "        lstm_q = self.drop_out(lstm_q)\n",
    "        \n",
    "        # Local inference modeling\n",
    "        # 矩阵乘法：最后两个维度可乘，前面所有维度保持一致\n",
    "        # [batch_size, seq_len, hidden_size] * [batch_size, seq_len, hidden_size]\n",
    "        # [seq_len, hidden_size] * [seq_len, hidden_size]\n",
    "        # [seq_len, hidden_size] * [hidden_size, seq_len]\n",
    "        # print('lstm_p', lstm_p.shape, lstm_p)\n",
    "        # print('lstm_q', lstm_q.shape, lstm_q)\n",
    "        e = torch.matmul(lstm_p, torch.transpose(lstm_q, 1, 2) )\n",
    "        # [seq_len, seq_len_p, seq_len_q]\n",
    "        # print('p*q矩阵', e.shape, e)\n",
    "        \n",
    "        # attention\n",
    "        p_hat = torch.matmul(torch.softmax(e, dim=2), lstm_q)\n",
    "        q_hat = torch.matmul(torch.transpose(torch.softmax(e, dim=1), 1, 2), lstm_p)\n",
    "        #q_hat = torch.matmul(torch.softmax(e, dim=1), lstm_p)\n",
    "        # print('p_hat', p_hat)\n",
    "        # print('q_hat', q_hat)\n",
    "        # raise Exception(\"ERR\")\n",
    "        \n",
    "        p_cat = torch.cat([lstm_p, p_hat, lstm_p-p_hat, lstm_p*p_hat], dim=-1)\n",
    "        q_cat = torch.cat([lstm_q, q_hat, lstm_q-q_hat, lstm_q*q_hat], dim=-1)\n",
    "        \n",
    "        # inference Composition\n",
    "        p, _ = self.context_lstm(p_cat)\n",
    "        q, _ = self.context_lstm(q_cat)\n",
    "        \n",
    "        # predict\n",
    "        p_max = self.max_pool(p).squeeze(dim=1)\n",
    "        q_max = self.max_pool(q).squeeze(dim=1)\n",
    "        \n",
    "        p_mean = torch.mean(p, dim=1)\n",
    "        q_mean = torch.mean(q, dim=1)\n",
    "        \n",
    "        y = torch.cat([p_max, q_max, p_mean, q_mean], dim=-1)\n",
    "        y = self.drop_out(y)\n",
    "        \n",
    "        y = self.fc1(y)\n",
    "        y = torch.tanh(y)\n",
    "        y = self.drop_out(y)\n",
    "        y = self.fc2(y)\n",
    "        y = torch.sigmoid(y)\n",
    "        y = y.squeeze(dim=-1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1de8fd6-a3c5-450d-b04f-4594a467fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "895040e7-e5d2-468a-b66d-fd0b3a3ee007",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "max_len=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "198271fd-bf06-4aab-b416-94aed45aff32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESIM(\n",
       "  (embedding): Embedding(22429, 200)\n",
       "  (char_lstm): LSTM(200, 128, batch_first=True, bidirectional=True)\n",
       "  (context_lstm): LSTM(1024, 128, batch_first=True, bidirectional=True)\n",
       "  (max_pool): MaxPool2d(kernel_size=(10, 1), stride=(10, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (drop_out): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESIM(vocab_size=vocab_size,\n",
    "             char_dim=200,\n",
    "             char_hidden_size=128,\n",
    "             max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c03e0628-0a6e-4a94-a772-4e00f4f25266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一长度\n",
    "def padding_seq(X, max_len=max_len):\n",
    "    return np.array([\n",
    "        np.concatenate([x, [0] * (max_len - len(x))]) if len(x) < max_len else x[:max_len] for x in X\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "979e1a29-99a4-4a8d-90a4-689be47dd7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=128):\n",
    "    df = pd.read_csv('./data/LCQMC.csv')\n",
    "    train_df, eval_df = split_data(df)\n",
    "    train_p = df['sentence1']\n",
    "    train_q = df['sentence2']\n",
    "    train_y = df['label']\n",
    "    eval_p = eval_df['sentence1']\n",
    "    eval_q = eval_df['sentence2']\n",
    "    eval_y = eval_df['label']\n",
    "\n",
    "    train_p = padding_seq(train_p.apply(seq2index))\n",
    "    train_q = padding_seq(train_q.apply(seq2index))\n",
    "    train_y = np.array(train_y)\n",
    "\n",
    "    train_data_set = TensorDataset(torch.from_numpy(train_p),\n",
    "                                   torch.from_numpy(train_q),\n",
    "                                   torch.from_numpy(train_y))\n",
    "    train_data_loader = DataLoader(dataset=train_data_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    eval_p = padding_seq(eval_p.apply(seq2index))\n",
    "    eval_q = padding_seq(eval_q.apply(seq2index))\n",
    "    return train_data_loader, [eval_p, eval_q], eval_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "872ef186-5d4a-48a1-b46a-3cd7886cc5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ESIM(vocab_size=vocab_size,\n",
    "         # char_dim=200,\n",
    "         char_dim=10,\n",
    "         # char_hidden_size=128,\n",
    "         char_hidden_size=8,\n",
    "         max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91c862d2-8ef0-4163-882b-cc57370dcf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "def train():\n",
    "    global model\n",
    "\n",
    "    train_data_loader, eval_x, eval_y = load_data(128)\n",
    "    \n",
    "    eval_p = eval_x[0]\n",
    "    eval_q = eval_x[1]\n",
    "    eval_p = torch.from_numpy(eval_p)\n",
    "    eval_q = torch.from_numpy(eval_q)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        eval_p = eval_p.cuda()\n",
    "        eval_q = eval_q.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_func = nn.BCELoss()\n",
    "\n",
    "    best_acc = 0\n",
    "\n",
    "    for epoch in range(10):\n",
    "        for step, (b_p, b_q, b_y) in enumerate(train_data_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                b_p = b_p.cuda()\n",
    "                b_q = b_q.cuda()\n",
    "                b_y = b_y.cuda()\n",
    "\n",
    "            output = model(b_p.long(), b_q.long())\n",
    "\n",
    "            loss = loss_func(output, b_y.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # # 每个epoch跑完在计算准确率\n",
    "        # test_output = model(eval_p, eval_q)\n",
    "        # pred_y = (test_output.cpu().data.numpy() > 0.5).astype(int)\n",
    "        # accuracy = float((pred_y == eval_y).astype(int).sum()) / float(eval_y.size)\n",
    "        # if accuracy > best_acc:\n",
    "        #     best_acc = accuracy\n",
    "        #     torch.save(model, 'esim.p')\n",
    "        #     print('save model, accuracy: %.3f' % accuracy)\n",
    "        # print('Epoch: ', epoch, '| train loss: %.4f' % loss.cpu().data.numpy(),\n",
    "        #       '| test accuracy: %.3f' % accuracy)\n",
    "\n",
    "\n",
    "            if step % 500 == 0:\n",
    "                # Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; \n",
    "                # but got torch.DoubleTensor instead (while checking arguments for embedding)\n",
    "                # to long\n",
    "                test_output = model(eval_p.long(), eval_q.long())\n",
    "                pred_y = (test_output.cpu().data.numpy() > 0.5).astype(int)\n",
    "                accuracy = float((pred_y == eval_y).astype(int).sum()) / float(eval_y.size)\n",
    "                if accuracy > best_acc:\n",
    "                    best_acc = accuracy\n",
    "                    # torch.save(model, 'esim.p')\n",
    "                    # print('save model, accuracy: %.3f' % accuracy)\n",
    "                print('Epoch: ', epoch, '| train loss: %.4f' % loss.cpu().data.numpy(),\n",
    "                      '| test accuracy: %.3f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4370fa8-678d-4352-b356-2c870beef0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.3092 | test accuracy: 0.898\n",
      "Epoch:  0 | train loss: 0.2156 | test accuracy: 0.903\n",
      "Epoch:  0 | train loss: 0.2684 | test accuracy: 0.897\n",
      "Epoch:  0 | train loss: 0.3032 | test accuracy: 0.900\n",
      "Epoch:  1 | train loss: 0.3225 | test accuracy: 0.901\n",
      "Epoch:  1 | train loss: 0.3205 | test accuracy: 0.901\n",
      "Epoch:  1 | train loss: 0.2474 | test accuracy: 0.902\n",
      "Epoch:  1 | train loss: 0.2390 | test accuracy: 0.902\n",
      "Epoch:  2 | train loss: 0.2544 | test accuracy: 0.900\n",
      "Epoch:  2 | train loss: 0.2818 | test accuracy: 0.905\n",
      "Epoch:  2 | train loss: 0.2739 | test accuracy: 0.903\n",
      "Epoch:  2 | train loss: 0.2835 | test accuracy: 0.904\n",
      "Epoch:  3 | train loss: 0.2516 | test accuracy: 0.899\n",
      "Epoch:  3 | train loss: 0.2627 | test accuracy: 0.901\n",
      "Epoch:  3 | train loss: 0.2824 | test accuracy: 0.908\n",
      "Epoch:  3 | train loss: 0.3010 | test accuracy: 0.905\n",
      "Epoch:  4 | train loss: 0.2175 | test accuracy: 0.904\n",
      "Epoch:  4 | train loss: 0.2047 | test accuracy: 0.912\n",
      "Epoch:  4 | train loss: 0.2557 | test accuracy: 0.912\n",
      "Epoch:  4 | train loss: 0.2552 | test accuracy: 0.909\n",
      "Epoch:  5 | train loss: 0.2684 | test accuracy: 0.907\n",
      "Epoch:  5 | train loss: 0.3393 | test accuracy: 0.909\n",
      "Epoch:  5 | train loss: 0.2517 | test accuracy: 0.907\n",
      "Epoch:  5 | train loss: 0.3174 | test accuracy: 0.907\n",
      "Epoch:  6 | train loss: 0.2711 | test accuracy: 0.905\n",
      "Epoch:  6 | train loss: 0.1886 | test accuracy: 0.910\n",
      "Epoch:  6 | train loss: 0.2992 | test accuracy: 0.911\n",
      "Epoch:  6 | train loss: 0.3534 | test accuracy: 0.915\n",
      "Epoch:  7 | train loss: 0.3023 | test accuracy: 0.910\n",
      "Epoch:  7 | train loss: 0.1882 | test accuracy: 0.915\n",
      "Epoch:  7 | train loss: 0.2952 | test accuracy: 0.909\n",
      "Epoch:  7 | train loss: 0.2576 | test accuracy: 0.910\n",
      "Epoch:  8 | train loss: 0.2125 | test accuracy: 0.912\n",
      "Epoch:  8 | train loss: 0.2367 | test accuracy: 0.913\n",
      "Epoch:  8 | train loss: 0.2865 | test accuracy: 0.908\n",
      "Epoch:  8 | train loss: 0.2918 | test accuracy: 0.911\n",
      "Epoch:  9 | train loss: 0.2076 | test accuracy: 0.906\n",
      "Epoch:  9 | train loss: 0.2022 | test accuracy: 0.907\n",
      "Epoch:  9 | train loss: 0.2710 | test accuracy: 0.914\n",
      "Epoch:  9 | train loss: 0.2145 | test accuracy: 0.910\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ee26ff5-7c4f-491e-b660-8cdce459abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_new = torch.load('./esim.p')\n",
    "model_new = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caf76fcd-5842-4bfe-a2d5-e97313176ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESIM(\n",
       "  (embedding): Embedding(22429, 10)\n",
       "  (char_lstm): LSTM(10, 8, batch_first=True, bidirectional=True)\n",
       "  (context_lstm): LSTM(64, 8, batch_first=True, bidirectional=True)\n",
       "  (max_pool): MaxPool2d(kernel_size=(10, 1), stride=(10, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (drop_out): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6f2f7b3-f3b9-4e88-a87e-80ead0457389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfication_predicts(s1, s2):\n",
    "    s1 = seq2index(s1)\n",
    "    s1 = torch.from_numpy(padding_seq([s1])).long()\n",
    "    \n",
    "    s2 = seq2index(s2)\n",
    "    s2 = torch.from_numpy(padding_seq([s2])).long()\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    s1 = s1.to(device)\n",
    "    s2 = s2.to(device)\n",
    "    \n",
    "    \n",
    "    out = model_new(s1, s2)\n",
    "    # return out.data.cpu().numpy()\n",
    "    return out.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbcfe068-352a-4dc0-a5e8-564955c9456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"喜欢打篮球的男生喜欢什么样的女生\"\n",
    "s2 = \"爱打篮球的男生喜欢什么样的女生\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb1c6863-e2bc-467f-9a38-2526da729f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8217], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfication_predicts(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c5dbdde-1d3b-4da5-b06c-66d057ce668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"部落冲突游戏怎么找回\"\n",
    "s2 = \"部落冲突重置游戏\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14781e09-a6f3-4710-9185-cf9d88918a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0064], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfication_predicts(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49d7d3fc-a46a-4939-85fd-d2fab6456e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"大家觉得她好看吗\"\n",
    "s2 = \"大家觉得跑男好看吗\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70d47ce1-8ab3-4cc3-a1d9-4f223730abf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1598], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfication_predicts(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6093e66d-f83a-40ad-b2db-7c5146c840ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"人情债怎么还\"\n",
    "s2 = \"人情债怎么还？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e47f7149-77dd-4c9f-b3b4-9e9ee9614102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9267], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfication_predicts(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914e898-7685-4c31-9b0a-b047ced72d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
