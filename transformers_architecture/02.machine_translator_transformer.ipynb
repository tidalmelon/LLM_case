{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fbb38de-f4cd-4b84-91ed-9912a904542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import zhconv\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd512008-e9ec-4f2a-81c2-28e4b4fa28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./codes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376cece3-050e-4e1c-90e6-0715dfaed3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe9979a-e4db-4846-b3f4-c1a9b9ded79d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1aa5a-1960-4ad6-9622-4ebc1cb020f5",
   "metadata": {},
   "source": [
    "## load corpus\n",
    "\n",
    "load sentences pair in chinese and english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7497ff0a-b501-4b44-ba95-013b0b87e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    chi_list = []\n",
    "    eng_list = []\n",
    "    with open('./data/cmn.txt') as f:\n",
    "        for line in f:\n",
    "            eng_sent, chi_sent, _ = line.split('\\t')\n",
    "            \n",
    "            # traditional to simplified\n",
    "            # zhconv.convert('走開！', 'zh-cn')\n",
    "            chi_sent = zhconv.convert(chi_sent, 'zh-cn')\n",
    "            \n",
    "            chi_list.append(chi_sent)\n",
    "            eng_list.append(eng_sent)\n",
    "    return chi_list, eng_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7824679-dab3-4e28-a3ce-54fb294f53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_list, eng_list = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa14d69-65cd-4c6f-b1b0-e31fc503ce00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('嗨。', 'Hi.'), ('你好。', 'Hi.'), ('你用跑的。', 'Run.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(chi_list[:3], eng_list[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41435a34-f49c-4fe0-826d-7146916d2ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('你很容易把母语说得通顺流畅，却很容易把非母语说得不自然。',\n",
       "  \"It's very easy to sound natural in your own native language, and very easy to sound unnatural in your non-native language.\"),\n",
       " ('虽然我被公司解雇了，但是我还有点存款，所以目前不用担心生计问题。',\n",
       "  \"I got fired from the company, but since I have a little money saved up, for the time being, I won't have trouble with living expenses.\"),\n",
       " ('如果一个人在成人前没有机会习得目标语言，他对该语言的认识达到母语者程度的机会是相当小的。',\n",
       "  \"If a person has not had a chance to acquire his target language by the time he's an adult, he's unlikely to be able to reach native speaker level in that language.\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(chi_list[-3:], eng_list[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a166472-e708-42f5-aeba-f536bd8b436f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26a797-874f-4f22-a8f4-48d4e7cfd8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5ad6f-e3d7-468d-ace6-2dddffedf2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "168b9943-6736-4209-8aee-57addd2aca32",
   "metadata": {},
   "source": [
    "## data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d815a95-608f-40de-882a-ab108ffa3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_space(word):\n",
    "    if not word:\n",
    "        # None ''\n",
    "        return True\n",
    "    if word.isspace():\n",
    "        #\\t \\n \\r \\u202f \\xa0\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a34d7f-f0cd-40bd-88e4-ec1ec2b6e275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'recommend', 'item']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['', ' ', 'i' , 'recommend', 'item']\n",
    "[w for w in words if not is_space(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2e0128-da1d-4fce-b4f3-895263fb3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_space(text):\n",
    "    # for english only\n",
    "    # fill space before ,.!? which is convenient to tokenize\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "    \n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text)]\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9da2b81-3a20-467b-b338-ed6afac5e033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's very easy to sound natural in your own native language , and very easy to sound unnatural in your non-native language .\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_space(\"It's very easy to sound natural in your own native language, and very easy to sound unnatural in your non-native language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ef7edb1-1472-42f2-a316-f41586273227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(chi_list, eng_list):\n",
    "    \n",
    "    source = []\n",
    "    for sent in chi_list:\n",
    "        words = jieba.cut(sent)\n",
    "        words = [w for w in words if not is_space(w)]\n",
    "        source.append(words)\n",
    "        \n",
    "    target = []\n",
    "    for sent in eng_list:\n",
    "        sent = sent.lower()\n",
    "        sent = fill_space(sent)\n",
    "        words = sent.split(' ')\n",
    "        words = [w for w in words if not is_space(w)]\n",
    "        target.append(words)\n",
    "        \n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16f665-6ebd-4a77-9e0d-c158d914e088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a208996-08cd-40c9-b595-f28d6e862e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.410 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "source, target = tokenize(chi_list, eng_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fc62f12-8759-4dbd-ab1a-09582efa2c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['嗨', '。'], ['你好', '。'], ['你', '用', '跑', '的', '。'], ['住手', '！'], ['等等', '！']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c83258e-851c-4414-b770-28bc90ba45b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi', '.'], ['hi', '.'], ['run', '.'], ['stop', '!'], ['wait', '!']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824053e-2c46-4f44-97a6-5afd13130a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "757d22e3-c462-4477-b281-6075826b793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for sent_cn, sent_eng in zip(source, target):\n",
    "    arr.append([len(sent_cn), len(sent_eng)])\n",
    "arr = torch.tensor(arr, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce2e8c39-d8f5-4376-b6cf-3f66eeb94aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([30., 34.]),\n",
       "indices=tensor([29362, 29370]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8270e1bf-49cb-43c6-97c6-4c6e2b5c6cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.6265, 7.2073])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4667d443-2d4b-4a35-a994-f72c384daa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_steps = 10, is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e81de-abcf-496f-93a8-4b2793ef892e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2cda031-f9be-4cff-baf9-023fdfb53882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    \"\"\"vocabulary\"\"\"\n",
    "    \n",
    "    def __init__(self, tokens, min_freq=0, reserved_tokens=['<pad>', '<bos>', '<eos>']):\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "        self._token_freqs = sorted(Counter(tokens).items(), key=lambda x: x[1], reverse=True)\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
    "        \n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) -1\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token(indices)\n",
    "        return [self.idx_to_token[indice] for indice in indices]\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        # index for the unknown token\n",
    "        return 0\n",
    "    \n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b02c83d-40dd-41b7-a73e-51a30034e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = Vocab(source, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "tgt_vocab = Vocab(target, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d28d7a13-3046-46d9-aedd-b31cb703cd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab['<pad>'], src_vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f80c0a70-4f49-4aad-b6da-0b039748d19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab[['<unk>', '<pad>', '<bos>', '<eos>', '。']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fabd49-a2ad-40f4-8877-ca3482497e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4feda06-9719-4549-9cb5-e672b474ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"truncate or pad sequence\"\"\"\n",
    "    if len(line) > num_steps: \n",
    "        # trancate\n",
    "        return line[:num_steps]\n",
    "    return line + [padding_token] * (num_steps - len(line)) # pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d532bd26-d5b1-4ffe-a6bb-899e1c6bde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(lines, vocab, num_steps):\n",
    "    \"\"\"transfrom text sequence of machine traslation into minibatches.\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    arr = [ truncate_pad(l, num_steps, vocab['<pad>'])  for l in lines]\n",
    "    arr = torch.tensor(arr)\n",
    "    \n",
    "    valid_len = (arr != vocab['<pad>']).type(torch.int32).sum(dim=1)\n",
    "    \n",
    "    return arr, valid_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28d543ff-8c93-4b55-9f07-a1de1afb8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 128, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0aa0af1-7303-4493-bec2-3067dc5da8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_arr, src_valid_len = to_tensor(source, src_vocab, num_steps=num_steps)\n",
    "tgt_arr, tgt_valid_len = to_tensor(target, tgt_vocab, num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44aa2e84-ed15-4219-9e7b-40d7aea7a259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2500,    4,    3,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1210,    4,    3,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [   8,  112,  324,    6,    4,    3,    1,    1,    1,    1],\n",
       "         [4522,   72,    3,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [2501,   72,    3,    1,    1,    1,    1,    1,    1,    1]]),\n",
       " tensor([3, 3, 6, 3, 3]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_arr[:5], src_valid_len[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a33b7002-3f5c-4f23-b6c2-e02f7650dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataloader(arr_list, batch_size, is_train=True):\n",
    "    dataset = TensorDataset(*arr_list)\n",
    "    return DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9159b013-ddf8-4671-ac1d-46249be26145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 3, 6, 3, 3]), tensor([10, 10, 10, 10, 10]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_valid_len[:5], src_valid_len[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12444e67-2571-49fe-a461-466038cb7604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a55f91a-4214-4228-b65e-06691ae1a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = to_dataloader((src_arr, src_valid_len, tgt_arr, tgt_valid_len), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "489252a7-c6a8-4264-a9af-d85de0510f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10]) torch.Size([128]) torch.Size([128, 10]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for e in iter(dataloader):\n",
    "    print(e[0].shape, e[1].shape, e[2].shape, e[3].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51405e02-cbc0-4357-b07c-b3d4ff50a925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd1ee990-4c05-4237-9292-d5e70fdcdc9d",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965bebc8-6aa0-4c3b-bb54-45ba7d9f1e5c",
   "metadata": {},
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09419730-9ca4-499f-b489-ff4cfa023785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 创建一个足够长的P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a355c73-ff50-4746-8dc9-250515e476b8",
   "metadata": {},
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d17c4e0-c7d2-498d-a41f-960d60deed5d",
   "metadata": {},
   "source": [
    "## Add&Norm\n",
    "residual connection and layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "929a5974-72b9-41e0-b11d-1ccd93b6e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c70457-0cc5-472d-ae81-d9dc4dfdaaf2",
   "metadata": {},
   "source": [
    "## PositionwiseFFN\n",
    "positionwise feed-forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7beef7a-4b88-441b-9c76-1b4315ba4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d6f66-9778-4147-b386-558efd2d45c1",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebab9c91-583d-4c76-84ab-6d29770ca94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = common.MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "            use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8122d25-c801-452c-ba5f-0bea3b6b03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(common.Encoder):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[\n",
    "                i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a0740-e229-4ccd-8704-9104a70a4d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "652b836e-78e4-4445-9c47-42d2effcfbc3",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0413997e-a886-4ec5-ac93-2f1ec0aef228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = common.MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = common.MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "                                   num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此state[2][self.i]初始化为None。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            # dec_valid_lens的开头:(batch_size,num_steps),\n",
    "            # 其中每一行是[1,2,...,num_steps]\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "\n",
    "        # 自注意力\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # 编码器－解码器注意力。\n",
    "        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2d57e52-81db-4cf9-a539-9728ffac1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(common.AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            # 解码器自注意力权重\n",
    "            self._attention_weights[0][\n",
    "                i] = blk.attention1.attention.attention_weights\n",
    "            # “编码器－解码器”自注意力权重\n",
    "            self._attention_weights[1][\n",
    "                i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f565f-d7c6-4d4a-a07a-45214b80a2b7",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3ce7c31-68c5-4225-86f5-b660447082dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_steps = 10\n",
    "lr = 0.005\n",
    "num_epochs = 100\n",
    "\n",
    "num_hiddens = 32\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "\n",
    "device = common.try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44ec6b42-87e6-434e-8381-99c3e7230067",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "net = common.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df86fe-dcb3-49aa-8c0c-99feebe8ee0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3b5f28a-ec9c-4b3b-85ee-7b70c80d330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"Train a model for sequence to sequence.\"\"\"\n",
    "    \n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = common.MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = common.Timer()\n",
    "        metric = common.Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                               device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()  # Make the loss scalar for `backward`\n",
    "            common.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        print(f'epoch {epoch} loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "              f'tokens/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6ece048-fd4b-4bb2-a6db-c842e18c6da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.493, 50184.6 tokens/sec on cuda:0\n",
      "epoch 1 loss 0.396, 54745.0 tokens/sec on cuda:0\n",
      "epoch 2 loss 0.364, 55667.9 tokens/sec on cuda:0\n",
      "epoch 3 loss 0.344, 55739.7 tokens/sec on cuda:0\n",
      "epoch 4 loss 0.328, 55888.8 tokens/sec on cuda:0\n",
      "epoch 5 loss 0.315, 53381.9 tokens/sec on cuda:0\n",
      "epoch 6 loss 0.303, 54444.9 tokens/sec on cuda:0\n",
      "epoch 7 loss 0.292, 54526.9 tokens/sec on cuda:0\n",
      "epoch 8 loss 0.282, 56100.1 tokens/sec on cuda:0\n",
      "epoch 9 loss 0.273, 55739.1 tokens/sec on cuda:0\n",
      "epoch 10 loss 0.265, 56169.6 tokens/sec on cuda:0\n",
      "epoch 11 loss 0.258, 55569.7 tokens/sec on cuda:0\n",
      "epoch 12 loss 0.252, 54848.6 tokens/sec on cuda:0\n",
      "epoch 13 loss 0.246, 55099.9 tokens/sec on cuda:0\n",
      "epoch 14 loss 0.241, 55345.0 tokens/sec on cuda:0\n",
      "epoch 15 loss 0.236, 55521.7 tokens/sec on cuda:0\n",
      "epoch 16 loss 0.231, 55169.6 tokens/sec on cuda:0\n",
      "epoch 17 loss 0.227, 54947.8 tokens/sec on cuda:0\n",
      "epoch 18 loss 0.223, 55385.4 tokens/sec on cuda:0\n",
      "epoch 19 loss 0.220, 54577.6 tokens/sec on cuda:0\n",
      "epoch 20 loss 0.216, 53899.1 tokens/sec on cuda:0\n",
      "epoch 21 loss 0.213, 55650.1 tokens/sec on cuda:0\n",
      "epoch 22 loss 0.210, 55358.5 tokens/sec on cuda:0\n",
      "epoch 23 loss 0.207, 55092.3 tokens/sec on cuda:0\n",
      "epoch 24 loss 0.205, 55078.9 tokens/sec on cuda:0\n",
      "epoch 25 loss 0.202, 54936.1 tokens/sec on cuda:0\n",
      "epoch 26 loss 0.200, 55371.4 tokens/sec on cuda:0\n",
      "epoch 27 loss 0.197, 54745.2 tokens/sec on cuda:0\n",
      "epoch 28 loss 0.194, 56207.7 tokens/sec on cuda:0\n",
      "epoch 29 loss 0.193, 55793.1 tokens/sec on cuda:0\n",
      "epoch 30 loss 0.191, 55795.3 tokens/sec on cuda:0\n",
      "epoch 31 loss 0.188, 55835.2 tokens/sec on cuda:0\n",
      "epoch 32 loss 0.187, 54594.9 tokens/sec on cuda:0\n",
      "epoch 33 loss 0.185, 54297.3 tokens/sec on cuda:0\n",
      "epoch 34 loss 0.183, 53281.2 tokens/sec on cuda:0\n",
      "epoch 35 loss 0.182, 55434.9 tokens/sec on cuda:0\n",
      "epoch 36 loss 0.181, 56113.6 tokens/sec on cuda:0\n",
      "epoch 37 loss 0.179, 55443.4 tokens/sec on cuda:0\n",
      "epoch 38 loss 0.177, 54667.7 tokens/sec on cuda:0\n",
      "epoch 39 loss 0.176, 54621.7 tokens/sec on cuda:0\n",
      "epoch 40 loss 0.175, 54889.9 tokens/sec on cuda:0\n",
      "epoch 41 loss 0.174, 53837.7 tokens/sec on cuda:0\n",
      "epoch 42 loss 0.172, 55165.2 tokens/sec on cuda:0\n",
      "epoch 43 loss 0.171, 55335.2 tokens/sec on cuda:0\n",
      "epoch 44 loss 0.170, 55348.1 tokens/sec on cuda:0\n",
      "epoch 45 loss 0.169, 55357.6 tokens/sec on cuda:0\n",
      "epoch 46 loss 0.167, 55254.1 tokens/sec on cuda:0\n",
      "epoch 47 loss 0.167, 55276.6 tokens/sec on cuda:0\n",
      "epoch 48 loss 0.166, 54025.4 tokens/sec on cuda:0\n",
      "epoch 49 loss 0.165, 55613.9 tokens/sec on cuda:0\n",
      "epoch 50 loss 0.163, 55977.3 tokens/sec on cuda:0\n",
      "epoch 51 loss 0.162, 56158.2 tokens/sec on cuda:0\n",
      "epoch 52 loss 0.162, 56246.0 tokens/sec on cuda:0\n",
      "epoch 53 loss 0.161, 56096.1 tokens/sec on cuda:0\n",
      "epoch 54 loss 0.160, 55126.0 tokens/sec on cuda:0\n",
      "epoch 55 loss 0.159, 54746.5 tokens/sec on cuda:0\n",
      "epoch 56 loss 0.159, 54162.1 tokens/sec on cuda:0\n",
      "epoch 57 loss 0.157, 54899.2 tokens/sec on cuda:0\n",
      "epoch 58 loss 0.157, 55613.7 tokens/sec on cuda:0\n",
      "epoch 59 loss 0.156, 55618.1 tokens/sec on cuda:0\n",
      "epoch 60 loss 0.155, 55686.6 tokens/sec on cuda:0\n",
      "epoch 61 loss 0.155, 54747.7 tokens/sec on cuda:0\n",
      "epoch 62 loss 0.154, 54389.0 tokens/sec on cuda:0\n",
      "epoch 63 loss 0.153, 53461.9 tokens/sec on cuda:0\n",
      "epoch 64 loss 0.153, 54533.6 tokens/sec on cuda:0\n",
      "epoch 65 loss 0.152, 54694.9 tokens/sec on cuda:0\n",
      "epoch 66 loss 0.151, 54623.6 tokens/sec on cuda:0\n",
      "epoch 67 loss 0.151, 54857.7 tokens/sec on cuda:0\n",
      "epoch 68 loss 0.150, 55051.9 tokens/sec on cuda:0\n",
      "epoch 69 loss 0.150, 55296.8 tokens/sec on cuda:0\n",
      "epoch 70 loss 0.149, 53909.3 tokens/sec on cuda:0\n",
      "epoch 71 loss 0.149, 54488.3 tokens/sec on cuda:0\n",
      "epoch 72 loss 0.148, 54496.3 tokens/sec on cuda:0\n",
      "epoch 73 loss 0.147, 55201.1 tokens/sec on cuda:0\n",
      "epoch 74 loss 0.147, 56103.0 tokens/sec on cuda:0\n",
      "epoch 75 loss 0.146, 55769.8 tokens/sec on cuda:0\n",
      "epoch 76 loss 0.146, 55722.2 tokens/sec on cuda:0\n",
      "epoch 77 loss 0.146, 54831.5 tokens/sec on cuda:0\n",
      "epoch 78 loss 0.145, 56277.5 tokens/sec on cuda:0\n",
      "epoch 79 loss 0.145, 56107.8 tokens/sec on cuda:0\n",
      "epoch 80 loss 0.144, 54902.1 tokens/sec on cuda:0\n",
      "epoch 81 loss 0.143, 54423.5 tokens/sec on cuda:0\n",
      "epoch 82 loss 0.143, 55064.8 tokens/sec on cuda:0\n",
      "epoch 83 loss 0.143, 55895.9 tokens/sec on cuda:0\n",
      "epoch 84 loss 0.142, 54757.5 tokens/sec on cuda:0\n",
      "epoch 85 loss 0.142, 56059.5 tokens/sec on cuda:0\n",
      "epoch 86 loss 0.142, 55698.5 tokens/sec on cuda:0\n",
      "epoch 87 loss 0.141, 55383.6 tokens/sec on cuda:0\n",
      "epoch 88 loss 0.141, 54754.1 tokens/sec on cuda:0\n",
      "epoch 89 loss 0.141, 54597.0 tokens/sec on cuda:0\n",
      "epoch 90 loss 0.140, 54910.3 tokens/sec on cuda:0\n",
      "epoch 91 loss 0.140, 53837.1 tokens/sec on cuda:0\n",
      "epoch 92 loss 0.139, 55298.6 tokens/sec on cuda:0\n",
      "epoch 93 loss 0.139, 55339.0 tokens/sec on cuda:0\n",
      "epoch 94 loss 0.138, 54819.1 tokens/sec on cuda:0\n",
      "epoch 95 loss 0.139, 54925.5 tokens/sec on cuda:0\n",
      "epoch 96 loss 0.138, 55437.1 tokens/sec on cuda:0\n",
      "epoch 97 loss 0.138, 54372.0 tokens/sec on cuda:0\n",
      "epoch 98 loss 0.138, 54652.3 tokens/sec on cuda:0\n",
      "epoch 99 loss 0.137, 53674.2 tokens/sec on cuda:0\n"
     ]
    }
   ],
   "source": [
    "train_seq2seq(net, dataloader, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06cfa8d-13c0-49ac-8859-e6c51127db52",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da5a027b-a46e-4b8c-89d8-658f9b66e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"Predict for sequence to sequence.\"\"\"\n",
    "\n",
    "    # Set `net` to eval mode for inference\n",
    "    net.eval()\n",
    "    # print(src_sentence)\n",
    "    words = list(jieba.cut(src_sentence))\n",
    "    # print(words)\n",
    "    \n",
    "    src_tokens = src_vocab[ words ] + [src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    \n",
    "    # Add the batch axis\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # Add the batch axis\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # We use the token with the highest prediction likelihood as the input\n",
    "        # of the decoder at the next time step\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # Save attention weights (to be covered later)\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # Once the end-of-sequence token is predicted, the generation of the\n",
    "        # output sequence is complete\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc80573-9464-420d-aef1-a0f342311ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72b43698-4cf4-444a-8a5a-fffafd455972",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嗨。 => hi .\n",
      "你好。 => hi .\n",
      "你用跑的。 => you ran into the bank .\n",
      "住手！ => stop !\n",
      "等等！ => wait !\n",
      "等一下！ => wait !\n",
      "开始！ => it began .\n",
      "你好。 => hi .\n",
      "我试试。 => i try it .\n",
      "我赢了。 => i won .\n",
      "不会吧。 => let's not be not .\n",
      "干杯! => put a <unk> !\n",
      "知道了没有？ => no idea occurred for ?\n",
      "懂了吗？ => did you understand ?\n",
      "你懂了吗？ => have you understand ?\n",
      "他跑了。 => he ran away .\n",
      "跳进来。 => the <unk> absorbs water .\n",
      "我知道。 => i know .\n",
      "我退出。 => i quit .\n",
      "我不干了。 => i don't have done .\n",
      "我没事。 => i'm okay .\n",
      "我已经起来了。 => i've already .\n",
      "听着。 => listen to .\n",
      "不可能！ => it may not be done !\n",
      "没门！ => put a <unk> .\n",
      "你确定？ => are you sure ?\n",
      "谢谢！ => thanks !\n",
      "试试吧。 => try it .\n",
      "我们来试试。 => we try to try .\n",
      "为什么是我？ => why are i ?\n",
      "去问汤姆。 => ask tom .\n",
      "好棒！ => awesome !\n",
      "冷静点。 => calm down .\n",
      "公平点。 => be fair .\n",
      "友善点。 => be friendly .\n",
      "友好点。 => be friendly .\n",
      "和气点。 => <unk> and <unk> are <unk> .\n",
      "友善点。 => be friendly .\n",
      "联系我。 => let's contact with me .\n",
      "联系我们。 => let's contact us .\n",
      "进来。 => come in .\n",
      "找到汤姆。 => tom found tom .\n",
      "滚出去！ => put a <unk> .\n",
      "出去！ => let's go out !\n",
      "走开！ => leave away !\n",
      "滚！ => get lost !\n",
      "走开！ => leave away !\n",
      "回家。 => go home .\n",
      "回家吧。 => go home .\n",
      "再见！ => see you again .\n",
      "告辞！ => put a <unk> .\n",
      "坚持。 => hang on .\n",
      "等一下！ => wait !\n",
      "坚持。 => hang on .\n",
      "他来了。 => he was him .\n",
      "他跑。 => he runs .\n",
      "帮我一下。 => help me .\n",
      "帮帮我们吧！ => let's get our <unk> .\n",
      "去打汤姆。 => go to tom .\n",
      "坚持。 => hang on .\n",
      "抱抱汤姆！ => hug tom .\n",
      "请抱紧汤姆。 => please be <unk> tom .\n",
      "我同意。 => i agree with .\n",
      "我觉得很热。 => i think it's very hot .\n",
      "我生病了。 => i'm sick .\n",
      "我很难过。 => i'm sad .\n",
      "我很害羞。 => i'm shy .\n",
      "我湿了。 => i wet .\n",
      "没关系。 => it isn't ok .\n",
      "是我。 => i'm my acquaintance .\n",
      "来加入我们吧。 => let's join us .\n",
      "留着吧。 => keep it .\n",
      "吻我。 => kissing me .\n",
      "完美！ => perfect !\n",
      "再见！ => see you again .\n",
      "闭嘴！ => shut up !\n",
      "不管它。 => no sense .\n",
      "拿走吧。 => take it .\n",
      "告诉我！ => tell me !\n",
      "汤姆胜利了。 => tom won .\n",
      "醒醒！ => wake up !\n",
      "去清洗一下。 => go to wash .\n",
      "我们知道。 => we know .\n",
      "欢迎。 => welcome .\n",
      "谁赢了？ => who won ?\n",
      "为什么不？ => why don't i have ?\n",
      "你跑。 => you run .\n",
      "算你狠。 => you win .\n",
      "往后退点。 => take a step off .\n",
      "后退！ => take a step off .\n",
      "往后退点。 => take a step off .\n",
      "静静的，别动。 => don't move the horse .\n",
      "我一无所知。 => i don't have any idea .\n",
      "把他铐上。 => put <unk> .\n",
      "往前开。 => drive .\n",
      "走开！ => leave away !\n",
      "滚！ => get lost !\n",
      "趴下！ => put a <unk> .\n",
      "滚！ => get lost !\n",
      "滚。 => get lost .\n"
     ]
    }
   ],
   "source": [
    "num = 100\n",
    "for chn, eng in zip(chi_list[:num], eng_list[:num]):\n",
    "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
    "        net, chn, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{chn} => {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43583b6-2aac-4572-8e2f-486ae935b8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88fd86b2-d7f1-4bb1-8e14-ad62b9178cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汤姆试过还回泳衣来换成更大一号的，但是员工告诉他那是不被允许的。 => tom tried to show me a bigger size of the\n",
      "在十九世纪三十年代的大萧条时期，许多富人在股市崩盘中失去了一切。 => many older sister amassed a lot of the wealthy people\n",
      "我觉得当汤姆发现他买来的画是赝品的时候，他会很生气。 => i think tom found what he was going to be\n",
      "为了不被洪水冲走，有的人紧紧地抱着树干长达数个钟头。 => a <unk> <unk> <unk> <unk> <unk> <unk> <unk> to the\n",
      "这个工人本来应该在中午十二点到达, 但他被交通堵塞困住了几个小时。 => the workers been twelve months in the crime .\n",
      "我父母通常用法语对话，即使我母亲的母语是英语。 => my parents usually talks in french , but i generally\n",
      "就像马克·诺弗勒早期演唱的歌曲《金钱无用》一样，绝大多数的人依然高呼赞成“金钱无用论”。 => the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "假如你在老师讲课的时候再集中一点去听讲的话，你应该就能弄明白了。 => a little talks to the teacher caused the teacher on\n",
      "当汤姆开着他破旧的雷泽车来接女儿放学时，他的女儿假装不认识他。 => tom took a <unk> call him when he left her\n",
      "许多自然环境保护主义者担心持续屠杀鲸鱼正推动这些动物走向灭绝。 => many people beginning of whales is a lot of whales\n",
      "去年在菲律宾，地震和海啸造成了超过6000人的死亡。 => the waves crashed with the mountain in the waves crashed\n",
      "“又是汤姆的电话？” “嗯。最近他每天晚上都会打过来。当时就不该给他我的号码的。” => \"is the phone ?\" \"tom was ?\n",
      "我母亲的法语比我父亲的英语要好，所以他们通常用法语交流。 => my mother speaks english better than my mother can speak\n",
      "汤姆不知如何翻译“计算机”一词，因为同他谈话的人从未见过一台。 => tom didn't know how to translate a word , his\n",
      "汤姆不喜欢使用”有色人种“这个术语，因为他认为，根据这种说法白种人没有颜色。 => tom doesn't like the <unk> , which <unk> <unk> <unk>\n",
      "你不想涂防晒霜是你的问题，但是晒伤了不要来抱怨。 => you don't want to mind if you don't want to\n",
      "即使是现在，我偶尔还是想见到你。不是今天的你，而是我记忆中曾经的你。 => even if you want to see you , i occasionally\n",
      "你很容易把母语说得通顺流畅，却很容易把非母语说得不自然。 => you have a native language and shook alcoholic can speak\n",
      "虽然我被公司解雇了，但是我还有点存款，所以目前不用担心生计问题。 => although i was fired , but i was fired ,\n",
      "如果一个人在成人前没有机会习得目标语言，他对该语言的认识达到母语者程度的机会是相当小的。 => if no one had a chance of people have known\n"
     ]
    }
   ],
   "source": [
    "num = -20\n",
    "for chn, eng in zip(chi_list[num:], eng_list[num:]):\n",
    "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
    "        net, chn, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{chn} => {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b543f-f344-4475-9b99-317eb24a6518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e661538-d21f-4912-9d2d-6dd49379d189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我要去上学=>i want to go to school .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我要去上学\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e91c6c7-c033-4bc7-8e03-0d1bff27e547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多可爱啊！=>how cute !\n"
     ]
    }
   ],
   "source": [
    "sentence = \"多可爱啊！\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d33a5735-3ad7-498d-8077-936bb994b09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抓住他=>grab him .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"抓住他\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c5f813e-d3cd-4fd8-948c-657128ab7cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一名律师=>i'm a lawyer .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我是一名律师\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e53d136-662d-4d5f-b730-f6d9a5718562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一名程序员=>i'm a computer programmer .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我是一名程序员\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a649f527-d5b2-471f-8333-8f3e32cb1f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一名飞行员=>i'm a pilot .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我是一名飞行员\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51d976a3-6a75-42ca-be1b-4b0accc7be63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我在踢足球=>i play soccer .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我在踢足球\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c07bd-9ed9-40a5-816e-15401f01ec57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad236a-7a5f-40e2-a75a-7ccd729fc2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13262ce6-abfa-496e-b0e4-ab88800746d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af0aa85c-75ab-46bc-b5e5-0cd3f92b0f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我在飞=>i'm flying kites .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我在飞\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df356e-c19c-4532-960b-97a14b62a9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0417075a-b11f-411a-ab06-e79eff939963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b88f89-d813-44ec-9c50-49b31b794421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a1de1-f5e9-45d4-8d5b-0ab0aea48680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64852900-4456-437e-87a2-f03a836acdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41371b75-4848-4671-b64f-eb44ba661ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc8c99-4e05-4518-b4ab-d7d487b3d9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0bac2-7c20-40c4-8bc3-30210c3863e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a4c7c-8465-4fc8-a674-1ca3a24340a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6611e-0fdb-4dd2-a896-b88ca1c125ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de965fb-95ff-4cab-b98a-f25429aea217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb898e83-86d6-468e-ba0b-6caff5ce18b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac92ef-0d2f-4ca6-a553-f1e708de6d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee938d-a0ee-44e9-9662-4a19d846d8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9efd136-343f-447f-a860-d573323b27b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa645aba-2c33-4632-b42f-6d8ee27fa29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce43832-7da4-4e11-8ad1-961092f1b8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4523a39-dd10-43ef-a3d7-ed51556c619b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b2750-594a-4a68-bd4b-5579a216f3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4ccf2-b6fe-40ff-89a1-974594d20779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b68ca-84c7-4d8d-916b-9635b6f0f16f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59338cce-dc40-4c2e-8c9b-500439080f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
