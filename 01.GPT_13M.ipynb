{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04280da-9ee0-4ff9-8584-ba7f270d37e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23b0d433-c16c-4126-a9da-d83d9e152b53",
   "metadata": {},
   "source": [
    "> 训练语料[THUCTC/THUCNews/游戏/](http://thuctc.thunlp.org/#%E8%8E%B7%E5%8F%96%E9%93%BE%E6%8E%A5), 剔除字频小于100的. 其他字符全部保留.<br>\n",
    "> 总参数量 1300万, 在一张RTX3060上,训练了48小时左右."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec1bf4-0d6e-4e67-bf1c-dab788181f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b627eb6-6097-433e-ab53-fd52c98b6997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93790201-04dc-4707-a66c-dd6497ca69bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob, json\n",
    "import os, time, datetime, sys, signal, pickle\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# from optimizer import Adam16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d162f6-81f8-495e-93f3-d2013d858c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afc143d5-6489-448c-b4c6-299114b3e3a2",
   "metadata": {},
   "source": [
    "## 点积缩放注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349dafd-e578-4b70-84e3-461eca74284f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7704f8-2cdb-4fc9-a945-36670d9d45d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size, n_embd, dropout, block_size):\n",
    "        super().__init__()\n",
    "        # head_size = 384/n_head \n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        # 下三角真，等价于valid_lens\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = [16, 256, 384]\n",
    "        # T = seq_len\n",
    "        # [batch_size, seq_len, channel_dim]\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        w = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        # BTT 必定是一个方阵,所以使用下三角阵实现掩码\n",
    "        w = w.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        w = F.softmax(w, dim=-1) # (B, T, T)\n",
    "        w = self.dropout(w)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = w @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f7f7f6-d9cb-4c59-a1a6-64dfc0d2d22f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 384])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "head_test = Head(head_size=64, n_embd=384, dropout=0.2, block_size=256)\n",
    "x = torch.randn(16, 256, 384)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d38ceb0b-a013-4c96-a4da-51f25786b7ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_test(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87cd35-8e06-43bb-999c-149c53d4e90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d808e7c-cd09-493a-922a-3e749acbfede",
   "metadata": {},
   "source": [
    "> <font color=red>此处实现的点积缩放注意力过程:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483ac691-b297-4951-baf1-5583c950a5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f52f712-42c8-4987-b566-631aabd55815",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True],\n",
       "        [False, False,  True,  True],\n",
       "        [False, False, False,  True],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(4, 4)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25bcec5b-4155-4ab5-8bab-3a8f49cb3340",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randn( 2, 4, 4)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6103dd02-28f3-4bab-95df-d0b7565d0fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2952, -0.1414,  0.0954,  2.3579],\n",
       "         [-0.7269, -0.6404,  1.7583, -1.1488],\n",
       "         [ 0.8572, -1.4686, -0.0623,  0.2973],\n",
       "         [-0.4093, -0.7080,  0.5000, -0.6843]],\n",
       "\n",
       "        [[ 0.0481, -0.6847, -0.4713,  1.7480],\n",
       "         [-0.0438, -0.1857,  0.2502, -0.4137],\n",
       "         [ 0.2577, -0.3792, -1.3037,  1.5165],\n",
       "         [-0.2302, -1.4977, -0.8842, -0.5028]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "318f44d8-708e-4e42-b9ed-6ec1eef60a37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2952,    -inf,    -inf,    -inf],\n",
       "         [-0.7269, -0.6404,    -inf,    -inf],\n",
       "         [ 0.8572, -1.4686, -0.0623,    -inf],\n",
       "         [-0.4093, -0.7080,  0.5000, -0.6843]],\n",
       "\n",
       "        [[ 0.0481,    -inf,    -inf,    -inf],\n",
       "         [-0.0438, -0.1857,    -inf,    -inf],\n",
       "         [ 0.2577, -0.3792, -1.3037,    -inf],\n",
       "         [-0.2302, -1.4977, -0.8842, -0.5028]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = w.masked_fill(tril[:4, :4] == 0, float('-inf'))\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7771224-708a-49a4-9da7-8786950a3ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4784, 0.5216, 0.0000, 0.0000],\n",
       "         [0.6683, 0.0653, 0.2665, 0.0000],\n",
       "         [0.2006, 0.1488, 0.4981, 0.1524]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5354, 0.4646, 0.0000, 0.0000],\n",
       "         [0.5751, 0.3042, 0.1207, 0.0000],\n",
       "         [0.3902, 0.1098, 0.2029, 0.2971]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(w, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca5e19-ecd1-4cb7-b9a4-ba4346af6cd0",
   "metadata": {},
   "source": [
    "> <font color=green>在seq_len维度,既句子维度,每次都掩蔽1个单词,形成一个下三角阵</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9331f-df40-4a7d-999f-aeb8d6d07997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829ac05-991a-4188-be9f-413999e57a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4b23b-6257-4b48-be97-96862fe9f0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac53cd-047d-4bac-80bf-c9e60897f5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e84a3b0-4ab6-4677-accf-4da7660963bb",
   "metadata": {},
   "source": [
    "## 多头注意力机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fc7b48-b99c-4dba-905b-712b7c38fca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, n_head, head_size, n_embd, dropout, block_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size, n_embd, dropout, block_size) for _ in range(n_head)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 这里的多头注意力是可以并行计算的,这里选择的是串行, 这里可以改为并行么?在decoder阶段.\n",
    "        # x = BTC, h(x)=BTC\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        # out = [B, T, C*n_head] = [batch_size, seq_len, (384/6)*6] =  [16, 256, 384]\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b688be-3642-4f7c-b032-870c12a2a1df",
   "metadata": {},
   "source": [
    "## 基于位置的前馈神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee2246ed-2f38-4e2f-a3ba-2ffdb7642247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f882b-5b5e-4c6e-b363-264391f1dee1",
   "metadata": {},
   "source": [
    "## GPT Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d89d57-79b6-4d7d-946d-6268cf2f3f0f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "928824c0-d781-4068-9a1e-ef310eb16f30",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](./imgs/gpt_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cbd5990-d5f2-4153-b22d-1f2a2d3e1721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head, dropout, block_size):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, n_embd, dropout, block_size)\n",
    "        self.ffwd = FeedFoward(n_embd, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52162b76-fa6a-40a3-8367-f06291b29360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bcdc064-d7c1-413c-b69e-5d81f374a674",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GPT 训练用语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4734c710-4107-4e19-b57a-16595adb8d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, n_head, n_layer, vocab_size, dropout, block_size, device):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head, dropout, block_size) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        self.device = device\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=self.device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def top_k_logits(logits, k) -> torch.Tensor:\n",
    "        if k == 0:\n",
    "            return logits\n",
    "        values, _ = torch.topk(logits, k)\n",
    "        min_values = values[:, -1]\n",
    "        return torch.where(logits < min_values, torch.ones_like(logits, dtype=logits.dtype) * -1e10, logits)\n",
    "        \n",
    "    def generate(self, idx, max_new_tokens, temperature: float = 1.0, top_k: int = 0) -> torch.Tensor:\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -self.block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] / temperature # becomes (B, C)\n",
    "            # apply top-k sampling\n",
    "            # logits = self.top_k_logits(logits, k=top_k)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e006e77-1adf-4a3e-ba23-2672327f9376",
   "metadata": {},
   "source": [
    "## 构建GPT训练用语言模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d00ab-44a3-466c-9d73-36b89d6983a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "851f262d-c115-40ae-8e2c-df45483fd8b6",
   "metadata": {},
   "source": [
    "[数据下载地址](http://thuctc.thunlp.org/#%E8%8E%B7%E5%8F%96%E9%93%BE%E6%8E%A5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f2e2a-89dc-482e-a5ca-f88baf7d18f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9653986-d4f5-4853-aec9-94c485724846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/mnt/Wangquanjun/DATA/THUCTC/THUCNews/游戏/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f29033df-ec12-4687-9574-5c842d6b382a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/Wangquanjun/DATA/THUCTC/THUCNews/游戏/425201.txt',\n",
       " '/mnt/Wangquanjun/DATA/THUCTC/THUCNews/游戏/413773.txt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_arr = glob.glob(data_path+'*.txt')\n",
    "path_arr[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f92c103-d36f-4e5f-8f57-b19e09251383",
   "metadata": {},
   "source": [
    "### 统计词频 & 去掉低频词\n",
    "> 基于字符的统计,因此不需要分词. <br>\n",
    "> 不使用停用词, 空格都是需要保留的.<br>\n",
    "> <font color=green>低频词需要去掉</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "661c468c-9918-48bd-951b-8df64c22b908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 最小词频:小于最小词频的词将被过滤掉\n",
    "MIN_FREQ = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62f57735-030a-4f0f-a871-a331375c34d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ch_freq = {}\n",
    "lines = []\n",
    "for path in path_arr:\n",
    "    with open(path, 'r', encoding='utf-8-sig') as f:\n",
    "        line = f.read()\n",
    "        # 去掉特殊的空白字符,归一化为' ' \n",
    "        line = line.strip().replace(u'\\u3000', ' ').replace(u'\\xa0', u' ').replace(u'\\u202f', u' ')\n",
    "        lines.append(line)\n",
    "        for ch in line:\n",
    "            if ch not in ch_freq:\n",
    "                ch_freq[ch] = 0\n",
    "            ch_freq[ch] += 1\n",
    "ch_freq = {k: v for k, v in sorted(ch_freq.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3f7cc59-f690-4486-8130-177172578f21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5817"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ch_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8b4de5e-403f-40bd-818f-d4a797762cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabs = []\n",
    "for ch , num in ch_freq.items():\n",
    "    if num > MIN_FREQ:\n",
    "        vocabs.append(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8684f4f2-69cc-4dc3-8f81-206ac3a2de9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2941"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb6184-c6c6-4aca-ab53-e9ce1c2bfdc6",
   "metadata": {},
   "source": [
    "### stoi itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6975042f-4012-4baf-86c8-46d6dec5fb07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(vocabs)}\n",
    "itos = {i:ch for i, ch in enumerate(vocabs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05c441bb-6ca0-418a-86d3-fbd7c933f8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/model/stoi.pk', 'wb') as f:\n",
    "    pickle.dump(stoi, f)\n",
    "    \n",
    "with open('./models/model/itos.pk', 'wb') as f:\n",
    "    pickle.dump(itos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b4b4f-ea30-4891-9e69-b903a7056235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf6e95-a182-4b32-94c6-363d9d6f1300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eff5757-23b8-40da-9871-83ab5a2acb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SET_CHAR_LIST = set(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46088a6f-208b-40b6-b7ce-b6493e2d66f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = ''\n",
    "val_data = ''\n",
    "for line in lines:\n",
    "    line = ''.join([ch for ch in line if ch in SET_CHAR_LIST])\n",
    "    n = int(0.9 * len(line))\n",
    "    train_data += line[:n]\n",
    "    val_data += line[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64d046-3742-45e7-9900-bbc53b05edc6",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f271b1e7-ff26-4ae8-a0ed-96119b64e195",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2941"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocabs)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2340637a-56d1-475e-b361-52167026c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "n_embd = 384 # embedding size (dimensionality of the hidden state)\n",
    "n_head = 6 # number of heads in multi-head attention in pytorch\n",
    "n_layer = 6 # number of layers in the transformer model\n",
    "dropout = 0.2 # dropout rate (probability of zeroing out activations)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1937c7de-b2be-496c-90ab-e04ddd292d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters for training (will be written to the data cache file)\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "eval_interval = 2000 # how often to evaluate the model on train and val sets\n",
    "# eval_interval = 20 # how often to evaluate the model on train and val sets\n",
    "max_iters = 2000_000\n",
    "# max_iters = 2000\n",
    "learning_rate = 3e-4 # 3e-4 is the default in the original paper \n",
    "eval_iters = 200 # how many batches to use for evaluation\n",
    "\n",
    "models_path = './models/model'\n",
    "average_power_usage = 550 # watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe1e49-0402-4787-9af1-101a89c605e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4f36b82-b6a5-4384-92f6-b0b94302d29f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = torch.tensor([stoi[ch] for ch in train_data], dtype=torch.long)\n",
    "val_data = torch.tensor([stoi[ch] for ch in val_data], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "373c2059-95c5-45b3-839b-19dfca68dab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19185178])\n",
      "torch.Size([2143728])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aaf15e-aa8f-43ea-87f8-4907bd8c9a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d1eca81-1f30-489d-8cd0-73947910c115",
   "metadata": {},
   "source": [
    "#### 方案-1: \n",
    "> <font color=red>内存占用太大</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0019b8a-e2ea-4751-a0f1-e8a27a74c5db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "0 tensor([0, 1, 2]) tensor([1, 2, 3])\n",
      "1 tensor([1, 2, 3]) tensor([2, 3, 4])\n",
      "2 tensor([2, 3, 4]) tensor([3, 4, 5])\n",
      "3 tensor([3, 4, 5]) tensor([4, 5, 6])\n",
      "4 tensor([4, 5, 6]) tensor([5, 6, 7])\n",
      "5 tensor([5, 6, 7]) tensor([6, 7, 8])\n",
      "6 tensor([6, 7, 8]) tensor([7, 8, 9])\n",
      "7 tensor([7, 8, 9]) tensor([ 8,  9, 10])\n",
      "8 tensor([ 8,  9, 10]) tensor([ 9, 10, 11])\n",
      "9 tensor([ 9, 10, 11]) tensor([10, 11, 12])\n",
      "10 tensor([10, 11, 12]) tensor([11, 12, 13])\n",
      "11 tensor([11, 12, 13]) tensor([12, 13, 14])\n",
      "12 tensor([12, 13, 14]) tensor([13, 14, 15])\n",
      "13 tensor([13, 14, 15]) tensor([14, 15, 16])\n",
      "14 tensor([14, 15, 16]) tensor([15, 16, 17])\n",
      "15 tensor([15, 16, 17]) tensor([16, 17, 18])\n",
      "16 tensor([16, 17, 18]) tensor([17, 18, 19])\n",
      "tensor([0, 1, 2])\n",
      "tensor([1, 2, 3])\n",
      "torch.Size([17, 3])\n"
     ]
    }
   ],
   "source": [
    "arr = torch.arange(20)\n",
    "print(arr)\n",
    "b_s = 3\n",
    "arr_x = []\n",
    "arr_y = []\n",
    "for i in range(arr.__len__()-b_s):\n",
    "    x = arr[i: i+b_s]\n",
    "    y = arr[i+1: i+1+b_s]\n",
    "    print(i, x, y)\n",
    "    arr_x.append(x)\n",
    "    arr_y.append(y)\n",
    "\n",
    "print(torch.stack(arr_x, dim=0)[0])\n",
    "print(torch.stack(arr_y, dim=0)[0])\n",
    "print(torch.stack(arr_x, dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "676d01f6-0e86-4a75-b6aa-35045a225553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GptDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, block_size):\n",
    "        arr_x = []\n",
    "        arr_y = []\n",
    "        for i in range(data.__len__()-block_size):\n",
    "            x = data[i: i+block_size]\n",
    "            y = data[i+1: i+1+block_size]\n",
    "            arr_x.append(x)\n",
    "            arr_y.append(y)\n",
    "    \n",
    "        self.x = torch.stack(arr_x, dim=0)\n",
    "        self.y = torch.stack(arr_y, dim=0)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb86d60-05ac-4ee1-8343-87e1a505ccf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = GptDataset(train_data, block_size=block_size)\n",
    "val_dataset = GptDataset(val_data, block_size=block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5da18-1002-4ef2-9e7c-c10eabac6898",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e33d7b-e8a5-49d6-b94f-0c50491ea93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(LBC_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3aa6bb-c305-42cc-8496-837988b64672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeebd2cb-96d5-4301-b505-74d3bce6329e",
   "metadata": {},
   "source": [
    "#### 方案-2: 随机抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65e9c791-de14-495e-98d0-3606e1d1b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(batch_size=16, block_size=256, device=None):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(len(train_data) - block_size, (batch_size,))\n",
    "    x = torch.stack([train_data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([train_data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc4683e1-93f6-44a5-93a6-ab0fc2dec271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_batch(batch_size=16, block_size=256, device=None):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(len(val_data) - block_size, (batch_size,))\n",
    "    x = torch.stack([val_data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([val_data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3991031-7ec3-4d36-8b16-5c15676f47a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 256])\n",
      "torch.Size([16, 256])\n"
     ]
    }
   ],
   "source": [
    "x, y = get_train_batch(device=device)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77cc03-cdaf-400b-8837-dba98a4b4009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41eff1e-38b8-43a6-b93d-c9d2d0d5b037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdba20ee-aa8b-487f-bdf0-45ffb65425e7",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245bd6b-6c77-42c9-bf27-630018aa94c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2a1bc04-0072-41f1-83be-1db7cd477f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "n_embd = 384 # embedding size (dimensionality of the hidden state)\n",
    "n_head = 6 # number of heads in multi-head attention in pytorch\n",
    "n_layer = 6 # number of layers in the transformer model\n",
    "dropout = 0.2 # dropout rate (probability of zeroing out activations)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vocab_size = 2941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767476c1-5348-497a-b832-1d7ed783097b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4063b1b3-0781-4668-b180-f8ddfa5a0a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7133d-02b7-456a-a23a-730be09fa36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9b34219-2047-403b-a1b0-a63b346e4f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPTLanguageModel(n_embd=n_embd,\n",
    "                         n_head=n_head,\n",
    "                         n_layer=n_layer,\n",
    "                         vocab_size=vocab_size,\n",
    "                         dropout=dropout,\n",
    "                         block_size=block_size,\n",
    "                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04649b0f-4861-44a0-8b50-814897048a74",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTLanguageModel(\n",
       "  (token_embedding_table): Embedding(2941, 384)\n",
       "  (position_embedding_table): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=384, out_features=2941, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544e9e5f-a79c-4141-b30a-8420b31f1cf4",
   "metadata": {},
   "source": [
    "Partially added support for training at fp16 precision for decreased memory usage ([source](https://gist.github.com/ajbrock/075c0ca4036dc4d8581990a6e76e07a3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c244235-4593-42d8-8131-94b895c6f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adam16(model.parameters(), lr=learning_rate) # for fp16\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09a9cf-0d05-48e7-b64d-ce58aea9bd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71621142-5193-4483-8c0c-ddfbcd7845c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_last_checkpoint(suffix: str = \"last\"):\n",
    "    \"\"\" Saves the model and training state to disk \"\"\"\n",
    "    torch.save(model.state_dict(), os.path.join(models_path, f\"model-{suffix}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a07c98c6-15f4-4c44-a6d4-bbda1b0e9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "best_score = None\n",
    "iter_range = range(max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e736b346-8400-4ea9-acb8-dc109bdcc211",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "t2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832d9a6-9146-41fb-a0ee-029fca84fff0",
   "metadata": {},
   "source": [
    "> valid loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0915763d-3df2-44ec-aacc-49b952e3f576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def estimate_loss(model, eval_iters, batch_size, block_size, device=None):\n",
    "    model.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    with torch.no_grad():\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_val_batch(batch_size=batch_size, block_size=block_size, device=device)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "    model.train()\n",
    "    return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb5b091b-fb30-4ba7-a859-e5706dd27e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 2000000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f1b3b-a227-4e2c-9a52-6bf53901380a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " evaluation took 4.52 seconds. model saved in 0.05 seconds. Total time wasted training: 0:00:09, approx. 0.001 kWh used, remaining time: 0.00 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:02:50, approx. 0.026 kWh used, remaining time: 47.21 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:05:31, approx. 0.051 kWh used, remaining time: 45.92 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:08:12, approx. 0.075 kWh used, remaining time: 45.47 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:10:53, approx. 0.100 kWh used, remaining time: 45.23 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:13:35, approx. 0.125 kWh used, remaining time: 45.07 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:16:16, approx. 0.149 kWh used, remaining time: 44.94 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:18:57, approx. 0.174 kWh used, remaining time: 44.83 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:21:38, approx. 0.198 kWh used, remaining time: 44.74 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:24:20, approx. 0.223 kWh used, remaining time: 44.66 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:27:01, approx. 0.248 kWh used, remaining time: 44.59 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:29:42, approx. 0.272 kWh used, remaining time: 44.52 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.10 seconds. Total time wasted training: 0:32:23, approx. 0.297 kWh used, remaining time: 44.46 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 0:35:04, approx. 0.322 kWh used, remaining time: 44.39 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 0:37:46, approx. 0.346 kWh used, remaining time: 44.33 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 0:40:27, approx. 0.371 kWh used, remaining time: 44.28 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 0:43:08, approx. 0.395 kWh used, remaining time: 44.22 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 0:45:49, approx. 0.420 kWh used, remaining time: 44.16 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 0:48:30, approx. 0.445 kWh used, remaining time: 44.11 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 0:51:11, approx. 0.469 kWh used, remaining time: 44.06 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 0:53:53, approx. 0.494 kWh used, remaining time: 44.01 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 0:56:34, approx. 0.519 kWh used, remaining time: 43.96 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 0:59:15, approx. 0.543 kWh used, remaining time: 43.91 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:01:56, approx. 0.568 kWh used, remaining time: 43.86 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:04:38, approx. 0.592 kWh used, remaining time: 43.81 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:07:19, approx. 0.617 kWh used, remaining time: 43.76 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:10:00, approx. 0.642 kWh used, remaining time: 43.71 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:12:41, approx. 0.666 kWh used, remaining time: 43.66 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.13 seconds. Total time wasted training: 1:15:22, approx. 0.691 kWh used, remaining time: 43.61 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:18:03, approx. 0.716 kWh used, remaining time: 43.56 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:20:44, approx. 0.740 kWh used, remaining time: 43.51 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:23:25, approx. 0.765 kWh used, remaining time: 43.47 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:26:07, approx. 0.789 kWh used, remaining time: 43.42 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:28:48, approx. 0.814 kWh used, remaining time: 43.37 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:31:29, approx. 0.839 kWh used, remaining time: 43.32 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:34:10, approx. 0.863 kWh used, remaining time: 43.27 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:36:51, approx. 0.888 kWh used, remaining time: 43.23 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:39:32, approx. 0.912 kWh used, remaining time: 43.18 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:42:13, approx. 0.937 kWh used, remaining time: 43.13 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 1:47:35, approx. 0.986 kWh used, remaining time: 43.04 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 1:50:17, approx. 1.011 kWh used, remaining time: 43.00 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 1:52:58, approx. 1.036 kWh used, remaining time: 42.95 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:01:03, approx. 1.110 kWh used, remaining time: 42.82 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:03:44, approx. 1.134 kWh used, remaining time: 42.77 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:06:26, approx. 1.159 kWh used, remaining time: 42.73 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:09:07, approx. 1.184 kWh used, remaining time: 42.69 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:11:49, approx. 1.208 kWh used, remaining time: 42.64 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:14:31, approx. 1.233 kWh used, remaining time: 42.60 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:17:12, approx. 1.258 kWh used, remaining time: 42.55 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:19:54, approx. 1.282 kWh used, remaining time: 42.51 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:22:35, approx. 1.307 kWh used, remaining time: 42.46 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:25:16, approx. 1.332 kWh used, remaining time: 42.42 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:27:58, approx. 1.356 kWh used, remaining time: 42.37 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:30:40, approx. 1.381 kWh used, remaining time: 42.33 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:33:21, approx. 1.406 kWh used, remaining time: 42.29 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:36:03, approx. 1.430 kWh used, remaining time: 42.24 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:38:44, approx. 1.455 kWh used, remaining time: 42.20 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:41:25, approx. 1.480 kWh used, remaining time: 42.15 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:44:07, approx. 1.504 kWh used, remaining time: 42.11 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:46:48, approx. 1.529 kWh used, remaining time: 42.06 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:49:30, approx. 1.554 kWh used, remaining time: 42.02 hours.\n",
      " evaluation took 4.51 seconds. model saved in 0.11 seconds. Total time wasted training: 2:52:11, approx. 1.578 kWh used, remaining time: 41.97 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:54:52, approx. 1.603 kWh used, remaining time: 41.93 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 2:57:34, approx. 1.628 kWh used, remaining time: 41.88 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 3:00:15, approx. 1.652 kWh used, remaining time: 41.84 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 3:02:57, approx. 1.677 kWh used, remaining time: 41.79 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 3:05:38, approx. 1.702 kWh used, remaining time: 41.75 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 3:08:20, approx. 1.726 kWh used, remaining time: 41.70 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 3:11:01, approx. 1.751 kWh used, remaining time: 41.66 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 3:13:42, approx. 1.776 kWh used, remaining time: 41.61 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 3:16:24, approx. 1.800 kWh used, remaining time: 41.57 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 3:19:05, approx. 1.825 kWh used, remaining time: 41.52 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 3:21:47, approx. 1.850 kWh used, remaining time: 41.48 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 3:24:28, approx. 1.874 kWh used, remaining time: 41.43 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 3:48:41, approx. 2.096 kWh used, remaining time: 41.03 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 9:11:32, approx. 5.056 kWh used, remaining time: 35.65 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 9:14:13, approx. 5.080 kWh used, remaining time: 35.60 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 9:16:55, approx. 5.105 kWh used, remaining time: 35.56 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 9:19:36, approx. 5.130 kWh used, remaining time: 35.51 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 9:22:18, approx. 5.154 kWh used, remaining time: 35.47 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 9:24:59, approx. 5.179 kWh used, remaining time: 35.42 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 9:27:41, approx. 5.204 kWh used, remaining time: 35.38 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 9:30:22, approx. 5.228 kWh used, remaining time: 35.33 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 9:33:03, approx. 5.253 kWh used, remaining time: 35.29 hours.\n",
      " evaluation took 4.52 seconds. model saved in 0.11 seconds. Total time wasted training: 9:35:45, approx. 5.278 kWh used, remaining time: 35.24 hours.\n"
     ]
    }
   ],
   "source": [
    "for iter in iter_range:\n",
    "    \n",
    "    if iter % eval_interval == 0 or iter == max_iters -1:\n",
    "        t1 = time.time()\n",
    "        score = estimate_loss(model, \n",
    "                              eval_iters=eval_iters, \n",
    "                              batch_size=batch_size, \n",
    "                              block_size=block_size, \n",
    "                              device=device)\n",
    "        t2 = time.time()\n",
    "        if best_score is None:\n",
    "            best_score = score\n",
    "            \n",
    "        if score < best_score:\n",
    "            save_last_checkpoint('best-val')\n",
    "            \n",
    "        save_last_checkpoint()\n",
    "        \n",
    "        t3 = time.time()\n",
    "        if iter > 0:\n",
    "            remaining_time = ((time.time()-t0)/60/60) / iter * (max_iters-iter) # h\n",
    "        else:\n",
    "            remaining_time = 0.0\n",
    "        \n",
    "        power_used = (time.time()-t0)/60/60*average_power_usage/1000 # kWh\n",
    "        training_time = str(datetime.timedelta(seconds=int(time.time()-t0)))\n",
    "    \n",
    "        print(f\" evaluation took {t2-t1:.2f} seconds. model saved in {t3-t2:.2f} seconds. Total time wasted training: {training_time}, approx. {power_used:.3f} kWh used, remaining time: {remaining_time:.2f} hours.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    x, y = get_train_batch(batch_size, block_size, device)\n",
    "    logits, loss = model(x, y)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc76e2f-87a5-4999-ba49-072a607e2553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91ff2a1d-f0b5-4e45-9c68-1204347e81ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024ec4a-a1e4-4102-94ec-593cba45f813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff06c0-41ca-4577-bd4e-ac46654916a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec052f-f09c-47f4-ab39-c087daeae8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52ab1e-b19c-4076-b12e-e7d166ece86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8aeba-98e4-4fe4-9232-d3e571b5706b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c9d15-bb10-48d7-97ba-37a7edd21706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850074e6-a8f7-4c00-89d4-555f744e1f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b2829-940c-4e1b-bfcd-546b0b5b2bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33104875-6ddc-4de6-a5d4-7af62dc9c87d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbee56-ee10-46b0-a86a-d547083c09f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1af1aac-8972-4341-ba3a-3fb202efb5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/model/stoi.pk', 'rb') as f:\n",
    "    stoi = pickle.load(f)\n",
    "    \n",
    "with open('./models/model/itos.pk', 'rb') as f:\n",
    "    itos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74700b2-d559-4b1d-ac28-a9a982645987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fac248c-62a0-4f2c-8bb5-5338f2d874fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "n_embd = 384 # embedding size (dimensionality of the hidden state)\n",
    "n_head = 6 # number of heads in multi-head attention in pytorch\n",
    "n_layer = 6 # number of layers in the transformer model\n",
    "dropout = 0.2 # dropout rate (probability of zeroing out activations)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vocab_size = 2941\n",
    "batch_size = 4 # 返回4组解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4a82d-1569-4893-a6ab-709d15f001f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bcc8049c-b31e-4705-993b-4a2c43fc57fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPTLanguageModel(n_embd=n_embd,\n",
    "                         n_head=n_head,\n",
    "                         n_layer=n_layer,\n",
    "                         vocab_size=vocab_size,\n",
    "                         dropout=dropout,\n",
    "                         block_size=block_size,\n",
    "                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43d8305b-9789-4238-9053-13a300b3655c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型\n",
    "model_path = './models/model/model-best-val.pt'\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9c5ff5f-fef1-41e8-8117-8557468928cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTLanguageModel(\n",
       "  (token_embedding_table): Embedding(2941, 384)\n",
       "  (position_embedding_table): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (4): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (5): Head(\n",
       "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=384, out_features=2941, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584292d1-fda3-489f-933e-4d33a8187266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c85780-b68b-4c0f-8ecc-fa34ad29dcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534ae63-70e5-4485-8215-55d303f6ddfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72130915-a3b0-4caa-9cea-20be6474ca67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd1e41-1e8f-447c-9cd2-2c395f03cc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f66a2c1-37e4-483d-b308-a1726ff42031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsamples = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62aa75cc-9ca8-4b7e-92a4-690ede698823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d60592b-8556-40f5-97eb-af741d5ecf0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = '魔兽世界'\n",
    "context = encode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39be981e-0b90-407d-b494-4be50368941b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[249, 453, 131, 145]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617d4a5-1f9b-460d-a7f0-3cb1eacc862b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ae869-31d4-4690-8a9a-a47d1c504525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c2219e7-6707-4601-9491-5c43c3999ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context = torch.tensor(context, device=device).unsqueeze(0).repeat(batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "82b5006f-3161-471a-875b-6cd7be26110f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[249, 453, 131, 145],\n",
       "        [249, 453, 131, 145],\n",
       "        [249, 453, 131, 145],\n",
       "        [249, 453, 131, 145]], device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75b9fe-fb4d-433c-8841-ec1f1225e0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79847a5d-bbbb-4e81-acd3-6b26ce91e927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a761265-a1c2-491c-bbc4-46e5c6f07c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca182efb-4142-423c-86c5-b8a98845f7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07e44793-e179-466d-94f6-dc4c5996256a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "GPTLanguageModel                              [4, 4, 2941]              --\n",
       "├─Embedding: 1-1                              [4, 4, 384]               1,129,344\n",
       "├─Embedding: 1-2                              [4, 384]                  98,304\n",
       "├─Sequential: 1-3                             [4, 4, 384]               --\n",
       "│    └─Block: 2-1                             [4, 4, 384]               --\n",
       "│    │    └─LayerNorm: 3-1                    [4, 4, 384]               768\n",
       "│    │    └─MultiHeadAttention: 3-2           [4, 4, 384]               590,208\n",
       "│    │    └─LayerNorm: 3-3                    [4, 4, 384]               768\n",
       "│    │    └─FeedFoward: 3-4                   [4, 4, 384]               1,181,568\n",
       "│    └─Block: 2-2                             [4, 4, 384]               --\n",
       "│    │    └─LayerNorm: 3-5                    [4, 4, 384]               768\n",
       "│    │    └─MultiHeadAttention: 3-6           [4, 4, 384]               590,208\n",
       "│    │    └─LayerNorm: 3-7                    [4, 4, 384]               768\n",
       "│    │    └─FeedFoward: 3-8                   [4, 4, 384]               1,181,568\n",
       "│    └─Block: 2-3                             [4, 4, 384]               --\n",
       "│    │    └─LayerNorm: 3-9                    [4, 4, 384]               768\n",
       "│    │    └─MultiHeadAttention: 3-10          [4, 4, 384]               590,208\n",
       "│    │    └─LayerNorm: 3-11                   [4, 4, 384]               768\n",
       "│    │    └─FeedFoward: 3-12                  [4, 4, 384]               1,181,568\n",
       "│    └─Block: 2-4                             [4, 4, 384]               --\n",
       "│    │    └─LayerNorm: 3-13                   [4, 4, 384]               768\n",
       "│    │    └─MultiHeadAttention: 3-14          [4, 4, 384]               590,208\n",
       "│    │    └─LayerNorm: 3-15                   [4, 4, 384]               768\n",
       "│    │    └─FeedFoward: 3-16                  [4, 4, 384]               1,181,568\n",
       "│    └─Block: 2-5                             [4, 4, 384]               --\n",
       "│    │    └─LayerNorm: 3-17                   [4, 4, 384]               768\n",
       "│    │    └─MultiHeadAttention: 3-18          [4, 4, 384]               590,208\n",
       "│    │    └─LayerNorm: 3-19                   [4, 4, 384]               768\n",
       "│    │    └─FeedFoward: 3-20                  [4, 4, 384]               1,181,568\n",
       "│    └─Block: 2-6                             [4, 4, 384]               --\n",
       "│    │    └─LayerNorm: 3-21                   [4, 4, 384]               768\n",
       "│    │    └─MultiHeadAttention: 3-22          [4, 4, 384]               590,208\n",
       "│    │    └─LayerNorm: 3-23                   [4, 4, 384]               768\n",
       "│    │    └─FeedFoward: 3-24                  [4, 4, 384]               1,181,568\n",
       "├─LayerNorm: 1-4                              [4, 4, 384]               768\n",
       "├─Linear: 1-5                                 [4, 4, 2941]              1,132,285\n",
       "===============================================================================================\n",
       "Total params: 13,000,573\n",
       "Trainable params: 13,000,573\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 52.00\n",
       "===============================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 3.73\n",
       "Params size (MB): 52.00\n",
       "Estimated Total Size (MB): 55.73\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_data=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4099c-aa65-42e8-8f27-f2d319a25c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5945a6af-dc54-444b-865b-ba8d96ed4dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generated = model.generate(context, max_new_tokens=nsamples, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a286014-e495-41ff-b565-858094b51083",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "魔兽世界》(Works II)。\n",
      "  DOTA 是第一款RPG游戏，而最大的乐趣就是以丰富的游戏体验来投入这一个世界。玩家的真实情感令人难以置信，对于能够让玩家喜爱的游戏来一次包容了，也能够让玩家感受到真正的足球游戏的乐趣。我们仅仅可以将这一切列给玩家带来的乐趣和\n",
      "==================================================\n",
      "魔兽世界：翼妖王之怒》中的消息，但丁的剧情盈集于一个全新的角色，这也是一个全新的世界。\n",
      "  “我们是一个游戏的玩家，在我们的脑海里，我们总是会把游戏中的一些人物做出来让大家都说的好，但丁的作品会和身世都有一些，比如《魔兽世界》和《星际》都是一些怪异的游戏。我们在《\n",
      "==================================================\n",
      "魔兽世界》，借助于中国大陆获得冠军，并且在不断扩大海外为中国游戏玩家提供丰富的网游体验。同时，盛大游戏都进行的帮化、业界和玩家问流、产品的理念与传统文化的融合，得到了赞扬。中国网络游戏行业发展的管发力和持续的支持下，也是中国网游公司的一次大胆尝学和魅力不亚于玩家，\n",
      "==================================================\n",
      "魔兽世界》延迟、《星际争霸2》延于PC平台，所以在欧美已经推出了大量的版本，曾经在美国、中国等地上推出了《魔兽世界》，当然这里也不会就是一次全面的实现了。\n",
      "  对于一款暴雪人兽世界，暴雪不准备和玩家分享暴雪的建议，但是国内的游戏公司很强吸引他们的玩家和赞助商！\n",
      " \n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for result in generated:\n",
    "    response = decode(result.tolist())\n",
    "    print(response)\n",
    "    print('====='*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232aca74-26ca-4329-a0bd-ea217474b654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267dd172-8b95-4718-bbc5-6ad38d315162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8ebf89ef-87dd-4345-b3b4-3259024d80e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "刀剑神域》中的武器，还有可能是一把特种剑。\n",
      "  当然，游戏的武器和兵种也是都变成了的，玩家可以选择要使用的武器，这个武器只能是以前的武器，在游戏中花钱，就是用铁片武器打造武器。\n",
      "  同时，游戏的武器有两种模型，其中一种是开枪、弹枪，武器是随机弹道，但是这种模型的武\n",
      "==================================================\n",
      "刀剑神域》就是在韩国发行，而韩国公司只是一个非常的原始化。\n",
      "  此前，韩国网游业界也曾以“新”的方式收费了韩国网游业，但是韩国国内游戏业有着不错的表现，也许是一个成熟的产业。但是，韩国国内游戏业界的巨头们，大家会说的是中国玩家游戏是不是很喜欢他们呢？\n",
      "  Base\n",
      "==================================================\n",
      "刀剑神域OL\n",
      "  《剑网3》运营团队为广大剑卡迷准备了多重精彩活动，让大家感受武卡世界的精彩魅力。\n",
      "  【活动时间】：\n",
      "  10月15日起开启\n",
      "  【活动内容】：\n",
      "  1、活动期间，玩家只需要和其他玩家一同游秘，便可以参加，活动期间，玩家可以通过打怪获得更多的经验\n",
      "==================================================\n",
      "刀剑神域》中的一些修过程，让玩家感受3D画面的真实感。\n",
      "  2008年度ChinaJoy原创大赛“玩家最期待的竞大网络游戏”。这项“最受欢迎的竞大网络游戏”之称。\n",
      "  《精灵传说》是以“精灵传说”为背景，采用“精灵传说”设计竞分帮秀，技能非常多的，每一个精灵都有着\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "sentence = '刀剑神域'\n",
    "context = encode(sentence)\n",
    "context = torch.tensor(context, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
    "generated = model.generate(context, max_new_tokens=nsamples, temperature=0.7)\n",
    "for result in generated:\n",
    "    response = decode(result.tolist())\n",
    "    print(response)\n",
    "    print('====='*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59331d-2af3-46c6-8b6c-1f04c2053955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f475545c-c253-464a-9115-4256595152f7",
   "metadata": {},
   "source": [
    "## 结论：\n",
    "> 1. 语句还算通顺， 毕竟参数有限.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ccc1d-d484-471a-a02c-0e4f0006ed36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831641e-ebbb-4ab8-a1f6-8274ac9ec572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad4b4cb-68ef-4680-8f66-c948f5da4899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753631c8-e0c3-464a-80db-40fd44b626b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc11f8-86fb-4ccb-b99c-cc2017cdbb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e915e-8f4e-445f-917d-8d1efe1baa70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eadc354-bf68-4215-a744-f371cd860f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569412ab-5585-4d74-840d-fa7daf4cb21b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m105"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
